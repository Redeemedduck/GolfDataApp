---
phase: 04-monitoring-model-health
plan: 03
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - components/model_health.py
  - components/__init__.py
  - pages/5_ðŸ”¬_Model_Health.py
autonomous: true

must_haves:
  truths:
    - "User can view MAE trend chart showing prediction error over sessions"
    - "User can see current model info (version, training date, samples, MAE)"
    - "User sees drift alerts when consecutive drift sessions detected"
    - "User can trigger retraining from the health dashboard with success feedback"
    - "User sees feature importance bar chart for current model"
    - "Dashboard gracefully handles empty state (no model, no performance data)"
  artifacts:
    - path: "components/model_health.py"
      provides: "Model health dashboard component with MAE chart, feature importance, drift alerts"
      exports: ["render_model_health_dashboard"]
    - path: "components/__init__.py"
      provides: "Export for render_model_health_dashboard"
      contains: "render_model_health_dashboard"
    - path: "pages/5_ðŸ”¬_Model_Health.py"
      provides: "Standalone Model Health page accessible from Streamlit navigation"
      min_lines: 20
  key_links:
    - from: "components/model_health.py"
      to: "ml/monitoring/drift_detector.py"
      via: "DriftDetector for drift history and consecutive count"
      pattern: "DriftDetector"
    - from: "components/model_health.py"
      to: "ml/train_models.py"
      via: "get_model_info() for model metadata, DistancePredictor for retraining"
      pattern: "get_model_info"
    - from: "pages/5_ðŸ”¬_Model_Health.py"
      to: "components/model_health.py"
      via: "render_model_health_dashboard() call"
      pattern: "render_model_health_dashboard"
---

<objective>
Build the Model Health dashboard UI that shows drift history, feature importance, and retraining controls.

Purpose: Users need visual confirmation that their model is performing well (or degrading). Without a dashboard, drift detection runs silently in the background with no way for users to see trends, understand when retraining is needed, or take action. This plan delivers the user-facing monitoring interface (Success Criterion 3).

Output: Model health Streamlit component and standalone page with MAE trend chart, feature importance, drift alerts, and retrain button.
</objective>

<execution_context>
@/Users/max1/.claude/get-shit-done/workflows/execute-plan.md
@/Users/max1/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-monitoring-model-health/04-RESEARCH.md
@.planning/phases/04-monitoring-model-health/04-01-SUMMARY.md
@components/__init__.py
@components/retraining_ui.py
@ml/train_models.py
@ml/monitoring/__init__.py
@pages/2_ðŸ“Š_Dashboard.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create render_model_health_dashboard() component</name>
  <files>components/model_health.py, components/__init__.py</files>
  <action>
Create components/model_health.py following the existing component pattern (stateless render_* functions, Plotly for charts, Streamlit for layout).

Imports (with graceful degradation):
- streamlit, plotly.graph_objects, pandas, sqlite3, typing.Optional
- Try import: ml.train_models (DistancePredictor, get_model_info, DISTANCE_MODEL_PATH, HAS_MAPIE), ml (ML_AVAILABLE)
- Try import: ml.monitoring (DriftDetector)
- Try import: golf_db
- Set fallback values if any import fails

render_model_health_dashboard() function with 6 sections:

Section 1 - ML Availability Check:
If not ML_AVAILABLE, show st.warning about missing ML dependencies and return early.

Section 2 - Current Model Info:
Use get_model_info(DISTANCE_MODEL_PATH) for metadata. If no model, show st.info("No model trained yet") and return.
Display 4 st.metric columns: Model Version, Trained Date (YYYY-MM-DD), Training Samples (comma-formatted), Training MAE ("X.X yd").
Show R2 caption if available. Show interval status caption.

Section 3 - Drift Status Alert:
If DriftDetector available, instantiate and call get_consecutive_drift_count() and get_drift_history(limit=5).
- consecutive >= 3: st.error with "Model Drift Detected", MAE details, and retrain button (type="primary", key="health_retrain")
- any recent drift: st.warning with "Elevated Error Detected"
- else: st.success with "Model performing within expected range"

Retrain button triggers: DistancePredictor().train_with_intervals() or .train() (depending on HAS_MAPIE and data size), shows success with new MAE, calls st.rerun(). Wrapped in try/except.

Section 4 - MAE Trend Chart:
st.subheader("Prediction Error Trend")
Query model_performance table from golf_db.SQLITE_DB_PATH (ORDER BY timestamp ASC).
If empty, show st.info and skip. Otherwise create Plotly figure:
- Blue line+markers for session_mae (markers red if has_drift)
- Dashed gray line for baseline_mae
- Dotted green horizontal line at training MAE
- Layout: x=Date, y=MAE (yards), height=400, hovermode='x unified'
- Caption: blue=normal, red=drift

Section 5 - Feature Importance:
st.subheader("Feature Importance")
Load DistancePredictor, get feature_importances_ and _feature_names.
Create horizontal bar chart (Plotly go.Bar, orientation='h', marker_color='lightblue').
Sort by importance descending. Height=300.
Caption explaining higher scores = more contribution.
Handle gracefully if model not loadable or no feature importances.

Section 6 - Performance History Table:
st.subheader("Session History")
If perf_df not empty, display last 20 sessions in st.dataframe with columns:
Session, MAE (yd), Baseline (yd), Drift %, Status (Drift/OK).

Update components/__init__.py:
Add "from .model_health import render_model_health_dashboard" import line.
Add 'render_model_health_dashboard' to __all__ list.
  </action>
  <verify>
Run python -m py_compile components/model_health.py to confirm syntax.
Run python -c "from components import render_model_health_dashboard; print('Import OK')" to confirm import.
  </verify>
  <done>render_model_health_dashboard() component exists with 6 sections: ML check, model info metrics, drift alert with retrain button, MAE trend Plotly chart, feature importance bar chart, and session history table. All sections gracefully handle empty/missing data states.</done>
</task>

<task type="auto">
  <name>Task 2: Create Model Health page</name>
  <files>pages/5_ðŸ”¬_Model_Health.py</files>
  <action>
Create pages/5_Model_Health.py as a standalone Streamlit page following existing page patterns (pages/2_Dashboard.py and pages/4_AI_Coach.py).

Structure:
1. Module docstring describing the page purpose
2. Imports: streamlit, sys, pathlib.Path, golf_db, components.render_model_health_dashboard
3. sys.path.append for parent directory (matching existing pages)
4. st.set_page_config(page_title="Model Health - My Golf Lab", page_icon="ðŸ”¬", layout="wide")
5. golf_db.init_db()
6. st.title("ðŸ”¬ Model Health Monitor")
7. st.markdown description

Sidebar:
- Navigation links to Dashboard and AI Coach (using st.page_link matching existing pattern)
- st.divider()
- Quick model status: try import get_model_info, show version and MAE metrics if model exists, else show "No model trained"

Main area:
- Call render_model_health_dashboard()

The page follows the exact conventions of existing pages:
- sys.path.append for parent imports
- golf_db.init_db() called early
- Wide layout
- Sidebar navigation to related pages
- Emoji in filename for Streamlit auto-ordering
  </action>
  <verify>
Run python -m py_compile "pages/5_ðŸ”¬_Model_Health.py" to confirm syntax.
Run python -m unittest discover -s tests to verify no regressions.
  </verify>
  <done>Model Health page exists at pages/5_Model_Health.py with sidebar navigation, model status sidebar, and full dashboard rendering via render_model_health_dashboard(). Accessible from Streamlit navigation menu as the 5th page.</done>
</task>

</tasks>

<verification>
1. python -m py_compile components/model_health.py succeeds
2. python -m py_compile pages/5_Model_Health.py succeeds
3. from components import render_model_health_dashboard succeeds
4. python -m unittest discover -s tests has no regressions
5. Component handles all empty states: no model, no performance data, no ML dependencies
6. Retrain button in drift alert section triggers retraining flow
</verification>

<success_criteria>
- Model Health page accessible as 5th Streamlit page
- Dashboard shows current model info (version, date, samples, MAE) in metric cards
- MAE trend chart plots session error vs baseline with color-coded drift points
- Feature importance horizontal bar chart shows current model's feature weights
- Drift alert section shows appropriate message (green/yellow/red) based on drift status
- Retrain button triggers model training with progress spinner and success message
- All sections gracefully handle missing data (empty tables, no model, no ML deps)
</success_criteria>

<output>
After completion, create .planning/phases/04-monitoring-model-health/04-03-SUMMARY.md
</output>
