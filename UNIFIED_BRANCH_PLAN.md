# Unified Branch Integration Plan

**Branch:** `claude/unified-ai-docker-integration`
**Base:** `main` (production-ready with Gemini 3 Pro + MCP)
**Date:** 2025-12-24

## ğŸ¯ Objective

Create a unified branch combining:
1. **Main branch**: Gemini 3 Pro + BigQuery + MCP Control Plane
2. **Docker branch**: Full containerization + Claude AI in Streamlit
3. **New features**: Both Claude AND Gemini in Streamlit app

---

## âœ… Already Completed

### 1. Branch Created
- Created `claude/unified-ai-docker-integration` from `main`
- Preserves all production features from main

### 2. Docker Files Merged
- âœ… Dockerfile (multi-stage, optimized)
- âœ… docker-compose.yml
- âœ… .dockerignore
- âœ… DOCKER_GUIDE.md (comprehensive documentation)
- âœ… DOCKER_README.md
- âœ… DOCKER_SETUP_COMPLETE.md
- âœ… docker-quickstart.sh
- âœ… .env.docker.example

---

## ğŸ“‹ Still TODO

### 1. Enhance app.py with Dual AI
**Goal:** Add both Claude AND Gemini to Streamlit app

**Features to add:**
```python
# AI availability detection
ANTHROPIC_AVAILABLE = bool(os.getenv("ANTHROPIC_API_KEY"))
GEMINI_AVAILABLE = bool(os.getenv("GEMINI_API_KEY"))

# Model selector in AI Coach tab
models = [
    "Claude Sonnet",      # Conversational
    "Claude Opus",        # Best quality
    "Claude Haiku",       # Fastest
    "Gemini 3 Pro (Code)", # Code execution
    "Gemini Flash"         # Quick insights
]
```

**Reference Implementation:**
- See `claude/fix-supabase-gemini-issues-PXRya` branch app.py (lines 1-538)
- Has complete dual AI integration
- Includes session-aware context
- Robust error handling

### 2. Fix Supabase RLS Security
**Current Issue:** RLS policies only allow `authenticated` users, but app uses `anon` key

**Solution:** Add policies for `anon` role in `supabase_schema.sql`:

```sql
-- Add after line 67
CREATE POLICY "Allow anon to read shots"
ON shots FOR SELECT
TO anon
USING (true);

CREATE POLICY "Allow anon to insert shots"
ON shots FOR INSERT
TO anon
WITH CHECK (true);

CREATE POLICY "Allow anon to update shots"
ON shots FOR UPDATE
TO anon
USING (true);

CREATE POLICY "Allow anon to delete shots"
ON shots FOR DELETE
TO anon
USING (true);
```

### 3. Update Documentation

**CLAUDE.md updates needed:**
- Document dual AI integration in Streamlit
- Update architecture diagram
- Add Docker containerization section
- Document model selection feature

**New section to add:**
```markdown
### AI Coach (In-App)

The Streamlit app now includes an AI Coach tab with multiple models:

**Claude (Anthropic):**
- Sonnet: Balanced performance
- Opus: Best quality analysis
- Haiku: Fastest responses

**Gemini (Google):**
- 3 Pro (Code): Runs Python analysis on your data
- Flash: Quick conversational insights

**Setup:**
```bash
# Add to .env
ANTHROPIC_API_KEY=sk-ant-...
GEMINI_API_KEY=AIza...
```
```

### 4. Test Docker Build
```bash
# Build
docker-compose build

# Run
docker-compose up -d

# Test AI features
# - Import data
# - Try Claude models
# - Try Gemini models
# - Verify code execution works
```

---

## ğŸ—ï¸ Architecture Overview

### Current (Main Branch)
```
Uneekor API â†’ SQLite (local) â†’ Supabase (backup) â†’ BigQuery (analytics)
                                                         â†“
                                                   Gemini 3 Pro (scripts)
                                                         â†“
                                                 MCP Control Plane
```

### Target (Unified Branch)
```
                  â”Œâ”€ Docker Container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                                            â”‚
Uneekor API â”€â”€â”€â”€â”€â”€â”¼â†’ Streamlit App (app.py)                   â”‚
                  â”‚    â”œâ”€ Dashboard                           â”‚
                  â”‚    â”œâ”€ Shot Viewer                         â”‚
                  â”‚    â”œâ”€ Data Management                     â”‚
                  â”‚    â””â”€ ğŸ¤– AI Coach (NEW!)                  â”‚
                  â”‚         â”œâ”€ Claude Sonnet/Opus/Haiku       â”‚
                  â”‚         â””â”€ Gemini 3 Pro / Flash           â”‚
                  â”‚          â†“                                 â”‚
                  â”‚    SQLite (local-first)                   â”‚
                  â”‚          â†“                                 â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                      Supabase (cloud backup)
                             â†“
                      BigQuery (analytics)
                             â†“
                      MCP Control Plane
```

**Key Differences:**
1. âœ¨ **AI in App**: Both Claude and Gemini accessible from Streamlit
2. ğŸ³ **Docker**: Fully containerized with OrbStack optimization
3. ğŸ”„ **Same Data Flow**: Preserves existing Supabase + BigQuery pipeline
4. ğŸ”’ **Fixed RLS**: Secure anon policies

---

## ğŸ“¦ Dependencies

### Current (main branch)
```
streamlit
pandas
plotly
requests
supabase
python-dotenv
google-generativeai
```

### Needed Additions
```
anthropic          # For Claude AI
```

---

## ğŸš€ Implementation Steps

### Step 1: Update app.py (30 min)
1. Add AI detection (lines 10-28)
2. Add client initialization functions (lines 32-54)
3. Add session_summary generator (lines 56-82)
4. Add AI Coach tab (lines 318-537)
5. Test locally: `streamlit run app.py`

### Step 2: Fix Supabase RLS (5 min)
1. Update `supabase_schema.sql`
2. Run in Supabase SQL Editor
3. Verify with test insert

### Step 3: Update requirements.txt (1 min)
```bash
echo "anthropic" >> requirements.txt
```

### Step 4: Test Docker (10 min)
```bash
docker-compose build
docker-compose up -d
open http://localhost:8501
```

### Step 5: Update Documentation (15 min)
1. Update CLAUDE.md
2. Add AI Coach section
3. Update architecture diagrams
4. Document new features

### Step 6: Commit and Push (5 min)
```bash
git add -A
git commit -m "feat: unified branch with Docker + dual AI + RLS fixes"
git push -u origin claude/unified-ai-docker-integration
```

---

## ğŸ Benefits of Unified Branch

| Feature | Main | Docker | Unified |
|---------|------|--------|---------|
| Gemini 3 Pro | âœ… Scripts | âŒ | âœ… In-app |
| Claude AI | âŒ | âœ… In-app | âœ… In-app |
| Docker | âŒ | âœ… | âœ… |
| BigQuery | âœ… | âœ… | âœ… |
| MCP | âœ… | âŒ | âœ… |
| Supabase RLS | âš ï¸ Broken | âš ï¸ Broken | âœ… Fixed |
| Code Execution | âœ… Scripts | âŒ | âœ… In-app |

**Result:** Best of all worlds! ğŸ‰

---

## ğŸ“ Notes

- **Main branch** is production-ready base
- **Docker branch** has containerization + Claude
- **Feature branch** (claude/fix-supabase-gemini-issues-PXRya) has dual AI implementation
- **This branch** will combine all three

---

## ğŸ¤” Questions for User

1. **Keep Supabase?** Or switch to SQLite â†’ BigQuery only?
2. **Model preferences?** Should we default to Claude or Gemini?
3. **Docker resources?** Any specific CPU/memory limits needed?
4. **Deployment target?** Local only or cloud deployment planned?

---

## ğŸ“ Next Actions

**For User:**
1. Review this plan
2. Confirm architecture approach
3. Test Docker setup locally
4. Provide feedback on AI model selection

**For Implementation:**
1. Copy AI Coach code from feature branch
2. Fix Supabase RLS
3. Test end-to-end
4. Update all documentation
5. Create PR to main

---

## ğŸ”— Related Files

- Main implementation: `app.py`
- Database: `golf_db.py` (already has Supabase hybrid)
- AI scripts: `scripts/gemini_analysis.py`, `scripts/claude_analysis.py`
- Docker: All `DOCKER_*.md` files
- Schema: `supabase_schema.sql`

---

**Status:** Docker files merged âœ…
**Next:** Implement dual AI in app.py
**ETA:** 1 hour of focused work
