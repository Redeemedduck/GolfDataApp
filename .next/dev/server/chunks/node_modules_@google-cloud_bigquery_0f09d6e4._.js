module.exports = [
"[project]/node_modules/@google-cloud/bigquery/build/src/util.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.toArray = toArray;
exports.isObject = isObject;
exports.isString = isString;
exports.isArray = isArray;
exports.isDate = isDate;
exports.isBoolean = isBoolean;
exports.isNumber = isNumber;
/**
 * Convert a value to an array. Replacement to arrify
 * @internal
 */ function toArray(value) {
    if (value === null || value === undefined) {
        return [];
    }
    if (Array.isArray(value)) {
        return value;
    }
    if (typeof value === 'string') {
        return [
            value
        ];
    }
    if (typeof value[Symbol.iterator] === 'function') {
        return [
            ...value
        ];
    }
    return [
        value
    ];
}
/**
 * Check if value is an object.
 * @internal
 */ function isObject(value) {
    return value && [
        undefined,
        Object
    ].includes(value.constructor);
}
/**
 * Check if value is an object.
 * @internal
 */ function isString(value) {
    return Object.prototype.toString.call(value) === '[object String]';
}
/**
 * Check if value is an array.
 * @internal
 */ function isArray(value) {
    return Array.isArray(value);
}
/**
 * Check if value is an instance of Date.
 * @internal
 */ function isDate(value) {
    return value instanceof Date;
}
/**
 * Check if value is a boolean.
 * @internal
 */ function isBoolean(value) {
    return Object.prototype.toString.call(value) === '[object Boolean]';
}
/**
 * Check if value is a number.
 * @internal
 */ function isNumber(value) {
    return Object.prototype.toString.call(value) === '[object Number]';
} //# sourceMappingURL=util.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/rowBatch.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2022 Google LLC. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.RowBatch = exports.BATCH_LIMITS = void 0;
exports.BATCH_LIMITS = {
    maxBytes: 9 * 1024 * 1024,
    maxRows: 50000
};
/**
 * Call used to help batch rows.
 *
 * @private
 *
 * @param {BatchInsertOptions} options The batching options.
 */ class RowBatch {
    batchOptions;
    rows;
    callbacks;
    created;
    bytes;
    constructor(options){
        this.batchOptions = options;
        this.rows = [];
        this.callbacks = [];
        this.created = Date.now();
        this.bytes = 0;
    }
    /**
     * Adds a row to the current batch.
     *
     * @param {object} row The row to insert.
     * @param {InsertRowsCallback} callback The callback function.
     */ add(row, callback) {
        this.rows.push(row);
        this.callbacks.push(callback);
        this.bytes += Buffer.byteLength(JSON.stringify(row));
    }
    /**
     * Indicates if a given row can fit in the batch.
     *
     * @param {object} row The row in question.
     * @returns {boolean}
     */ canFit(row) {
        const { maxRows, maxBytes } = this.batchOptions;
        return this.rows.length < maxRows && this.bytes + Buffer.byteLength(JSON.stringify(row)) <= maxBytes;
    }
    /**
     * Checks to see if this batch is at the maximum allowed payload size.
     *
     * @returns {boolean}
     */ isAtMax() {
        const { maxRows, maxBytes } = exports.BATCH_LIMITS;
        return this.rows.length >= maxRows || this.bytes >= maxBytes;
    }
    /**
     * Indicates if the batch is at capacity.
     *
     * @returns {boolean}
     */ isFull() {
        const { maxRows, maxBytes } = this.batchOptions;
        return this.rows.length >= maxRows || this.bytes >= maxBytes;
    }
}
exports.RowBatch = RowBatch; //# sourceMappingURL=rowBatch.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/rowQueue.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2022 Google LLC. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.RowQueue = exports.defaultOptions = void 0;
const common = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
const crypto_1 = __turbopack_context__.r("[externals]/crypto [external] (crypto, cjs)");
const _1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/index.js [app-route] (ecmascript)");
const rowBatch_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/rowBatch.js [app-route] (ecmascript)");
exports.defaultOptions = {
    // The maximum number of rows we'll batch up for insert().
    maxOutstandingRows: 300,
    // The maximum size of the total batched up rows for insert().
    maxOutstandingBytes: 9 * 1024 * 1024,
    // The maximum time we'll wait to send batched rows, in milliseconds.
    maxDelayMillis: 10000
};
/**
 * Standard row queue used for inserting rows.
 *
 *
 * @param {Table} table The table.
 * @param {Duplex} dup Row stream.
 * @param {InsertStreamOptions} options Insert and batch options.
 */ class RowQueue {
    table;
    stream;
    insertRowsOptions = {};
    batch;
    batchOptions;
    inFlight;
    pending;
    constructor(table, dup, options){
        this.table = table;
        this.stream = dup;
        this.inFlight = false;
        const opts = typeof options === 'object' ? options : {};
        if (opts.insertRowsOptions) {
            this.insertRowsOptions = opts.insertRowsOptions;
        } else {
            this.insertRowsOptions = {};
        }
        if (opts.batchOptions) {
            this.setOptions(opts.batchOptions);
        } else {
            this.setOptions();
        }
        this.batch = new rowBatch_1.RowBatch(this.batchOptions);
    }
    /**
     * Adds a row to the queue.
     *
     * @param {RowMetadata} row The row to insert.
     * @param {InsertRowsCallback} callback The insert callback.
     */ add(row, callback) {
        if (!this.insertRowsOptions.raw) {
            row = {
                json: _1.Table.encodeValue_(row)
            };
            if (this.insertRowsOptions.createInsertId !== false) {
                row.insertId = (0, crypto_1.randomUUID)();
            }
        }
        if (!this.batch.canFit(row)) {
            this.insert();
        }
        this.batch.add(row, callback);
        if (this.batch.isFull()) {
            this.insert();
        } else if (!this.pending) {
            const { maxMilliseconds } = this.batchOptions;
            this.pending = setTimeout(()=>{
                this.insert();
            }, maxMilliseconds);
        }
    }
    /**
     * Cancels any pending inserts and calls _insert immediately.
     */ insert(callback) {
        const { rows, callbacks } = this.batch;
        this.batch = new rowBatch_1.RowBatch(this.batchOptions);
        if (this.pending) {
            clearTimeout(this.pending);
            delete this.pending;
        }
        if (rows.length > 0) {
            this._insert(rows, callbacks, callback);
        }
    }
    /**
     * Accepts a batch of rows and inserts them into table.
     *
     * @param {object[]} rows The rows to insert.
     * @param {InsertCallback[]} callbacks The corresponding callback functions.
     * @param {function} [callback] Callback to be fired when insert is done.
     */ _insert(rows, callbacks, cb) {
        const json = extend(true, {}, this.insertRowsOptions, {
            rows
        });
        delete json.createInsertId;
        delete json.partialRetries;
        delete json.raw;
        this.table.request({
            method: 'POST',
            uri: '/insertAll',
            json
        }, (err, resp)=>{
            const partialFailures = (resp?.insertErrors || []).map((insertError)=>{
                return {
                    errors: insertError.errors.map((error)=>{
                        return {
                            message: error.message,
                            reason: error.reason
                        };
                    }),
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    row: rows[insertError.index]
                };
            });
            if (partialFailures.length > 0) {
                err = new common.util.PartialFailureError({
                    errors: partialFailures,
                    response: resp
                });
                callbacks.forEach((callback)=>callback(err, resp));
                this.stream.emit('error', err);
            } else {
                callbacks.forEach((callback)=>callback(err, resp));
                this.stream.emit('response', resp);
                cb?.(err, resp);
            }
            cb?.(err, resp);
        });
    }
    /**
     * Sets the batching options.
     *
     *
     * @param {RowBatchOptions} [options] The batching options.
     */ setOptions(options = {}) {
        const defaults = this.getOptionDefaults();
        const { maxBytes, maxRows, maxMilliseconds } = extend(true, defaults, options);
        this.batchOptions = {
            maxBytes: Math.min(maxBytes, rowBatch_1.BATCH_LIMITS.maxBytes),
            maxRows: Math.min(maxRows, rowBatch_1.BATCH_LIMITS.maxRows),
            maxMilliseconds: maxMilliseconds
        };
    }
    getOptionDefaults() {
        // Return a unique copy to avoid shenanigans.
        const defaults = {
            maxBytes: exports.defaultOptions.maxOutstandingBytes,
            maxRows: exports.defaultOptions.maxOutstandingRows,
            maxMilliseconds: exports.defaultOptions.maxDelayMillis
        };
        return defaults;
    }
}
exports.RowQueue = RowQueue; //# sourceMappingURL=rowQueue.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/table.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2014 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Table = void 0;
const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const paginator_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/paginator/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/util.js [app-route] (ecmascript)");
const Big = __turbopack_context__.r("[project]/node_modules/big.js/big.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
const events_1 = __turbopack_context__.r("[externals]/events [external] (events, cjs)");
const fs = __turbopack_context__.r("[externals]/fs [external] (fs, cjs)");
const path = __turbopack_context__.r("[externals]/path [external] (path, cjs)");
const streamEvents = __turbopack_context__.r("[project]/node_modules/stream-events/index.js [app-route] (ecmascript)");
const crypto_1 = __turbopack_context__.r("[externals]/crypto [external] (crypto, cjs)");
const duplexify = __turbopack_context__.r("[project]/node_modules/duplexify/index.js [app-route] (ecmascript)");
const _1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/index.js [app-route] (ecmascript)");
const stream_1 = __turbopack_context__.r("[externals]/stream [external] (stream, cjs)");
const rowQueue_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/rowQueue.js [app-route] (ecmascript)");
/**
 * The file formats accepted by BigQuery.
 *
 * @type {object}
 * @private
 */ const FORMATS = {
    avro: 'AVRO',
    csv: 'CSV',
    export_metadata: 'DATASTORE_BACKUP',
    json: 'NEWLINE_DELIMITED_JSON',
    orc: 'ORC',
    parquet: 'PARQUET'
};
/**
 * Table objects are returned by methods such as
 * {@link Dataset#table}, {@link Dataset#createTable}, and
 * {@link Dataset#getTables}.
 *
 * @class
 * @param {Dataset} dataset {@link Dataset} instance.
 * @param {string} id The ID of the table.
 * @param {object} [options] Table options.
 * @param {string} [options.location] The geographic location of the table, by
 *      default this value is inherited from the dataset. This can be used to
 *      configure the location of all jobs created through a table instance. It
 *      cannot be used to set the actual location of the table. This value will
 *      be superseded by any API responses containing location data for the
 *      table.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 * const dataset = bigquery.dataset('my-dataset');
 *
 * const table = dataset.table('my-table');
 * ```
 */ class Table extends common_1.ServiceObject {
    dataset;
    bigQuery;
    location;
    rowQueue;
    createReadStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    constructor(dataset, id, options){
        const methods = {
            /**
             * @callback CreateTableCallback
             * @param {?Error} err Request error, if any.
             * @param {Table} table The table.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} CreateTableResponse
             * @property {Table} 0 The table.
             * @property {object} 1 The full API response body.
             */ /**
             * Create a table.
             *
             * @method Table#create
             * @param {object} [options] See {@link Dataset#createTable}.
             * @param {CreateTableCallback} [callback]
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Table} callback.table The new {@link Table}.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<CreateTableResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             *
             * const table = dataset.table('my-table');
             *
             * table.create((err, table, apiResponse) => {
             *   if (!err) {
             *     // The table was created successfully.
             *   }
             * });
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * table.create().then((data) => {
             *   const table = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ create: true,
            /**
             * @callback DeleteTableCallback
             * @param {?Error} err Request error, if any.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} DeleteTableResponse
             * @property {object} 0 The full API response.
             */ /**
             * Delete a table and all its data.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/v2/tables/delete| Tables: delete API Documentation}
             *
             * @method Table#delete
             * @param {DeleteTableCallback} [callback]
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<DeleteTableResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             *
             * const table = dataset.table('my-table');
             *
             * table.delete((err, apiResponse) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * table.delete().then((data) => {
             *   const apiResponse = data[0];
             * });
             * ```
             */ delete: true,
            /**
             * @callback TableExistsCallback
             * @param {?Error} err Request error, if any.
             * @param {boolean} exists Indicates if the table exists.
             */ /**
             * @typedef {array} TableExistsCallback
             * @property {boolean} 0 Indicates if the table exists.
             */ /**
             * Check if the table exists.
             *
             * @method Table#exists
             * @param {TableExistsCallback} [callback]
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {boolean} callback.exists Whether the table exists or not.
             * @returns {Promise<TableExistsCallback>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             *
             * const table = dataset.table('my-table');
             *
             * table.exists((err, exists) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * table.exists().then((data) => {
             *   const exists = data[0];
             * });
             * ```
             */ exists: true,
            /**
             * @callback GetTableCallback
             * @param {?Error} err Request error, if any.
             * @param {Table} table The table.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} GetTableResponse
             * @property {Table} 0 The table.
             * @property {object} 1 The full API response body.
             */ /**
             * Get a table if it exists.
             *
             * You may optionally use this to "get or create" an object by providing
             * an object with `autoCreate` set to `true`. Any extra configuration that
             * is normally required for the `create` method must be contained within
             * this object as well.
             *
             * If you wish to get a selection of metadata instead of the full table metadata
             * (retrieved by both Table#get by default and by Table#getMetadata), use
             * the `options` parameter to set the `view` and/or `selectedFields` query parameters.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/get#TableMetadataView| Tables.get and TableMetadataView }
             *
             * @method Table#get
             * @param {options} [options] Configuration object.
             * @param {boolean} [options.autoCreate=false] Automatically create the
             *     object if it does not exist.
             * @param {function} [callback]
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Table} callback.table The {@link Table}.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetTableResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             *
             * const table = dataset.table('my-table');
             *
             * const options = {
             *   view: "BASIC"
             * }
             *
             * table.get((err, table, apiResponse) => {
             *   // `table.metadata` has been populated.
             * });
             *
             * table.get(options, (err, table, apiResponse) => {
             *   // A selection of `table.metadata` has been populated
             * })
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * table.get().then((data) => {
             *   const table = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ get: true,
            /**
             * @callback GetTableMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The table metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} GetTableMetadataResponse
             * @property {object} 0 The table metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Return the metadata associated with the Table.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/v2/tables/get| Tables: get API Documentation}
             *
             * @method Table#getMetadata
             * @param {GetTableMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.metadata The metadata of the Table.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetTableMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             *
             * const table = dataset.table('my-table');
             *
             * table.getMetadata((err, metadata, apiResponse) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * table.getMetadata().then((data) => {
             *   const metadata = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ getMetadata: true
        };
        super({
            parent: dataset,
            baseUrl: '/tables',
            id,
            createMethod: dataset.createTable.bind(dataset),
            methods
        });
        if (options && options.location) {
            this.location = options.location;
        }
        this.bigQuery = dataset.bigQuery;
        this.dataset = dataset;
        // Catch all for read-modify-write cycle
        // https://cloud.google.com/bigquery/docs/api-performance#read-patch-write
        this.interceptors.push({
            request: (reqOpts)=>{
                if (reqOpts.method === 'PATCH' && reqOpts.json.etag) {
                    reqOpts.headers = reqOpts.headers || {};
                    reqOpts.headers['If-Match'] = reqOpts.json.etag;
                }
                return reqOpts;
            }
        });
        /**
         * Create a readable stream of the rows of data in your table. This method
         * is simply a wrapper around {@link Table#getRows}.
         *
         * See {@link https://cloud.google.com/bigquery/docs/reference/v2/tabledata/list| Tabledata: list API Documentation}
         *
         * @returns {ReadableStream}
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         * const dataset = bigquery.dataset('my-dataset');
         * const table = dataset.table('my-table');
         *
         * table.createReadStream(options)
         *   .on('error', console.error)
         *   .on('data', row => {})
         *   .on('end', function() {
         *     // All rows have been retrieved.
         *   });
         *
         * //-
         * // If you anticipate many results, you can end a stream early to prevent
         * // unnecessary processing and API requests.
         * //-
         * table.createReadStream()
         *   .on('data', function(row) {
         *     this.end();
         *   });
         * ```
         */ this.createReadStream = paginator_1.paginator.streamify('getRows');
    }
    /**
     * Convert a comma-separated name:type string to a table schema object.
     *
     * @static
     * @private
     *
     * @param {string} str Comma-separated schema string.
     * @returns {object} Table schema in the format the API expects.
     */ static createSchemaFromString_(str) {
        return str.split(',').reduce((acc, pair)=>{
            acc.fields.push({
                name: pair.split(':')[0].trim(),
                type: (pair.split(':')[1] || 'STRING').toUpperCase().trim()
            });
            return acc;
        }, {
            fields: []
        });
    }
    /**
     * Convert a row entry from native types to their encoded types that the API
     * expects.
     *
     * @static
     * @private
     *
     * @param {*} value The value to be converted.
     * @returns {*} The converted value.
     */ static encodeValue_(value) {
        if (typeof value === 'undefined' || value === null) {
            return null;
        }
        if (value instanceof Buffer) {
            return value.toString('base64');
        }
        if (value instanceof Big) {
            return value.toFixed();
        }
        const customTypeConstructorNames = [
            'BigQueryDate',
            'BigQueryDatetime',
            'BigQueryInt',
            'BigQueryTime',
            'BigQueryTimestamp',
            'BigQueryRange',
            'Geography'
        ];
        const constructorName = value.constructor?.name;
        const isCustomType = customTypeConstructorNames.indexOf(constructorName) > -1;
        if (isCustomType) {
            return value.value;
        }
        if ((0, util_1.isDate)(value)) {
            return value.toJSON();
        }
        if ((0, util_1.isArray)(value)) {
            return value.map(Table.encodeValue_);
        }
        if (typeof value === 'object') {
            return Object.keys(value).reduce((acc, key)=>{
                acc[key] = Table.encodeValue_(value[key]);
                return acc;
            }, {});
        }
        return value;
    }
    /**
     * @private
     */ static formatMetadata_(options) {
        const body = extend(true, {}, options);
        if (options.name) {
            body.friendlyName = options.name;
            delete body.name;
        }
        if ((0, util_1.isString)(options.schema)) {
            body.schema = Table.createSchemaFromString_(options.schema);
        }
        if ((0, util_1.isArray)(options.schema)) {
            body.schema = {
                fields: options.schema
            };
        }
        if (body.schema && body.schema.fields) {
            body.schema.fields = body.schema.fields.map((field)=>{
                if (field.fields) {
                    field.type = 'RECORD';
                }
                return field;
            });
        }
        if ((0, util_1.isString)(options.partitioning)) {
            body.timePartitioning = {
                type: options.partitioning.toUpperCase()
            };
            delete body.partitioning;
        }
        if ((0, util_1.isString)(options.view)) {
            body.view = {
                query: options.view,
                useLegacySql: false
            };
        }
        return body;
    }
    copy(destination, metadataOrCallback, cb) {
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        this.createCopyJob(destination, metadata, (err, job, resp)=>{
            if (err) {
                callback(err, resp);
                return;
            }
            job.on('error', callback).on('complete', (metadata)=>{
                callback(null, metadata);
            });
        });
    }
    copyFrom(sourceTables, metadataOrCallback, cb) {
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        this.createCopyFromJob(sourceTables, metadata, (err, job, resp)=>{
            if (err) {
                callback(err, resp);
                return;
            }
            job.on('error', callback).on('complete', (metadata)=>{
                callback(null, metadata);
            });
        });
    }
    createCopyJob(destination, metadataOrCallback, cb) {
        if (!(destination instanceof Table)) {
            throw new Error('Destination must be a Table object.');
        }
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        const body = {
            configuration: {
                copy: extend(true, metadata, {
                    destinationTable: {
                        datasetId: destination.dataset.id,
                        projectId: destination.dataset.projectId,
                        tableId: destination.id
                    },
                    sourceTable: {
                        datasetId: this.dataset.id,
                        projectId: this.dataset.projectId,
                        tableId: this.id
                    }
                })
            }
        };
        if (metadata.jobPrefix) {
            body.jobPrefix = metadata.jobPrefix;
            delete metadata.jobPrefix;
        }
        if (this.location) {
            body.location = this.location;
        }
        if (metadata.jobId) {
            body.jobId = metadata.jobId;
            delete metadata.jobId;
        }
        if (body.configuration && metadata.reservation) {
            body.configuration.reservation = metadata.reservation;
            delete metadata.reservation;
        }
        this.bigQuery.createJob(body, callback);
    }
    createCopyFromJob(source, metadataOrCallback, cb) {
        const sourceTables = (0, util_1.toArray)(source);
        sourceTables.forEach((sourceTable)=>{
            if (!(sourceTable instanceof Table)) {
                throw new Error('Source must be a Table object.');
            }
        });
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        const body = {
            configuration: {
                copy: extend(true, metadata, {
                    destinationTable: {
                        datasetId: this.dataset.id,
                        projectId: this.dataset.projectId,
                        tableId: this.id
                    },
                    sourceTables: sourceTables.map((sourceTable)=>{
                        return {
                            datasetId: sourceTable.dataset.id,
                            projectId: sourceTable.dataset.projectId,
                            tableId: sourceTable.id
                        };
                    })
                })
            }
        };
        if (metadata.jobPrefix) {
            body.jobPrefix = metadata.jobPrefix;
            delete metadata.jobPrefix;
        }
        if (this.location) {
            body.location = this.location;
        }
        if (metadata.jobId) {
            body.jobId = metadata.jobId;
            delete metadata.jobId;
        }
        if (body.configuration && metadata.reservation) {
            body.configuration.reservation = metadata.reservation;
            delete metadata.reservation;
        }
        this.bigQuery.createJob(body, callback);
    }
    createExtractJob(destination, optionsOrCallback, cb) {
        let options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        options = extend(true, options, {
            destinationUris: (0, util_1.toArray)(destination).map((dest)=>{
                if (!common_1.util.isCustomType(dest, 'storage/file')) {
                    throw new Error('Destination must be a File object.');
                }
                // If no explicit format was provided, attempt to find a match from the
                // file's extension. If no match, don't set, and default upstream to
                // CSV.
                const format = path.extname(dest.name).substr(1).toLowerCase();
                if (!options.destinationFormat && !options.format && FORMATS[format]) {
                    options.destinationFormat = FORMATS[format];
                }
                return 'gs://' + dest.bucket.name + '/' + dest.name;
            })
        });
        if (options.format) {
            options.format = options.format.toLowerCase();
            if (FORMATS[options.format]) {
                options.destinationFormat = FORMATS[options.format];
                delete options.format;
            } else {
                throw new Error('Destination format not recognized: ' + options.format);
            }
        }
        if (options.gzip) {
            options.compression = 'GZIP';
            delete options.gzip;
        }
        const body = {
            configuration: {
                extract: extend(true, options, {
                    sourceTable: {
                        datasetId: this.dataset.id,
                        projectId: this.dataset.projectId,
                        tableId: this.id
                    }
                })
            }
        };
        if (options.jobPrefix) {
            body.jobPrefix = options.jobPrefix;
            delete options.jobPrefix;
        }
        if (this.location) {
            body.location = this.location;
        }
        if (options.jobId) {
            body.jobId = options.jobId;
            delete options.jobId;
        }
        if (body.configuration && options.reservation) {
            body.configuration.reservation = options.reservation;
            delete options.reservation;
        }
        this.bigQuery.createJob(body, callback);
    }
    createLoadJob(source, metadataOrCallback, cb) {
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        this._createLoadJob(source, metadata).then(([resp])=>callback(null, resp, resp.metadata), (err)=>callback(err));
    }
    /**
     * @param {string | File | File[]} source
     * @param {JobLoadMetadata} metadata
     * @returns {Promise<JobResponse>}
     * @private
     */ async _createLoadJob(source, metadata) {
        if (metadata.format) {
            metadata.sourceFormat = FORMATS[metadata.format.toLowerCase()];
            delete metadata.format;
        }
        if (this.location) {
            metadata.location = this.location;
        }
        if (typeof source === 'string') {
            // A path to a file was given. If a sourceFormat wasn't specified, try to
            // find a match from the file's extension.
            const detectedFormat = FORMATS[path.extname(source).substr(1).toLowerCase()];
            if (!metadata.sourceFormat && detectedFormat) {
                metadata.sourceFormat = detectedFormat;
            }
            // Read the file into a new write stream.
            const jobWritable = fs.createReadStream(source).pipe(this.createWriteStream_(metadata));
            const [jobResponse] = await (0, events_1.once)(jobWritable, 'job');
            return [
                jobResponse,
                jobResponse.metadata
            ];
        }
        const body = {
            configuration: {
                load: {
                    destinationTable: {
                        projectId: this.dataset.projectId,
                        datasetId: this.dataset.id,
                        tableId: this.id
                    }
                }
            }
        };
        if (metadata.jobPrefix) {
            body.jobPrefix = metadata.jobPrefix;
            delete metadata.jobPrefix;
        }
        if (metadata.location) {
            body.location = metadata.location;
            delete metadata.location;
        }
        if (metadata.jobId) {
            body.jobId = metadata.jobId;
            delete metadata.jobId;
        }
        if (body.configuration && metadata.reservation) {
            body.configuration.reservation = metadata.reservation;
            delete metadata.reservation;
        }
        extend(true, body.configuration?.load, metadata, {
            sourceUris: (0, util_1.toArray)(source).map((src)=>{
                if (!common_1.util.isCustomType(src, 'storage/file')) {
                    throw new Error('Source must be a File object.');
                }
                // If no explicit format was provided, attempt to find a match from
                // the file's extension. If no match, don't set, and default upstream
                // to CSV.
                const format = FORMATS[path.extname(src.name).substr(1).toLowerCase()];
                if (!metadata.sourceFormat && format && body.configuration && body.configuration.load) {
                    body.configuration.load.sourceFormat = format;
                }
                return 'gs://' + src.bucket.name + '/' + src.name;
            })
        });
        return this.bigQuery.createJob(body);
    }
    createQueryJob(options, callback) {
        return this.dataset.createQueryJob(options, callback);
    }
    /**
     * Run a query scoped to your dataset as a readable object stream.
     *
     * See {@link BigQuery#createQueryStream} for full documentation of this
     * method.
     *
     * @param {object} query See {@link BigQuery#createQueryStream} for full
     *     documentation of this method.
     * @returns {stream} See {@link BigQuery#createQueryStream} for full
     *     documentation of this method.
     */ createQueryStream(query) {
        return this.dataset.createQueryStream(query);
    }
    /**
     * Creates a write stream. Unlike the public version, this will not
     * automatically poll the underlying job.
     *
     * @private
     *
     * @param {string|object} [metadata] Metadata to set with the load operation.
     *     The metadata object should be in the format of the
     *     {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad| `configuration.load`}
     * property of a Jobs resource. If a string is given, it will be used
     * as the filetype.
     * @param {string} [metadata.jobId] Custom job id.
     * @param {string} [metadata.jobPrefix] Prefix to apply to the job id.
     * @returns {WritableStream}
     */ createWriteStream_(metadata) {
        metadata = metadata || {};
        if (typeof metadata === 'string') {
            metadata = {
                sourceFormat: FORMATS[metadata.toLowerCase()]
            };
        }
        if (typeof metadata.schema === 'string') {
            metadata.schema = Table.createSchemaFromString_(metadata.schema);
        }
        metadata = extend(true, {
            destinationTable: {
                projectId: this.dataset.projectId,
                datasetId: this.dataset.id,
                tableId: this.id
            }
        }, metadata);
        let jobId = metadata.jobId || (0, crypto_1.randomUUID)();
        if (metadata.jobId) {
            delete metadata.jobId;
        }
        if (metadata.jobPrefix) {
            jobId = metadata.jobPrefix + jobId;
            delete metadata.jobPrefix;
        }
        const dup = streamEvents(duplexify());
        const jobMetadata = {
            configuration: {
                load: metadata
            },
            jobReference: {
                jobId,
                projectId: this.dataset.projectId,
                location: this.location
            }
        };
        dup.once('writing', ()=>{
            common_1.util.makeWritableStream(dup, {
                makeAuthenticatedRequest: this.bigQuery.makeAuthenticatedRequest,
                metadata: jobMetadata,
                request: {
                    uri: `${this.bigQuery.apiEndpoint}/upload/bigquery/v2/projects/${this.dataset.projectId}/jobs`
                }
            }, (data)=>{
                let job = null;
                const jobRef = data.jobReference;
                if (jobRef && jobRef.jobId) {
                    job = this.bigQuery.job(jobRef.jobId, {
                        location: jobRef.location,
                        projectId: jobRef.projectId
                    });
                    job.metadata = data;
                }
                dup.emit('job', job);
            });
        });
        return dup;
    }
    /**
     * Load data into your table from a readable stream of AVRO, CSV, JSON, ORC,
     * or PARQUET data.
     *
     * See {@link https://cloud.google.com/bigquery/docs/reference/v2/jobs/insert| Jobs: insert API Documentation}
     *
     * @param {string|object} [metadata] Metadata to set with the load operation.
     *     The metadata object should be in the format of the
     *     {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad| `configuration.load`}
     * property of a Jobs resource. If a string is given,
     * it will be used as the filetype.
     * @param {string} [metadata.jobId] Custom job id.
     * @param {string} [metadata.jobPrefix] Prefix to apply to the job id.
     * @returns {WritableStream}
     *
     * @throws {Error} If source format isn't recognized.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('my-dataset');
     * const table = dataset.table('my-table');
     *
     * //-
     * // Load data from a CSV file.
     * //-
     * const request = require('request');
     *
     * const csvUrl = 'http://goo.gl/kSE7z6';
     *
     * const metadata = {
     *   allowJaggedRows: true,
     *   skipLeadingRows: 1
     * };
     *
     * request.get(csvUrl)
     *   .pipe(table.createWriteStream(metadata))
     *   .on('job', (job) => {
     *     // `job` is a Job object that can be used to check the status of the
     *     // request.
     *   })
     *   .on('complete', (job) => {
     *     // The job has completed successfully.
     *   });
     *
     * //-
     * // Load data from a JSON file.
     * //-
     * const fs = require('fs');
     *
     * fs.createReadStream('./test/testdata/testfile.json')
     *   .pipe(table.createWriteStream('json'))
     *   .on('job', (job) => {
     *     // `job` is a Job object that can be used to check the status of the
     *     // request.
     *   })
     *   .on('complete', (job) => {
     *     // The job has completed successfully.
     *   });
     * ```
     */ createWriteStream(metadata) {
        const stream = this.createWriteStream_(metadata);
        stream.on('prefinish', ()=>{
            stream.cork();
        });
        stream.on('job', (job)=>{
            job.on('error', (err)=>{
                stream.destroy(err);
            }).on('complete', ()=>{
                stream.emit('complete', job);
                stream.uncork();
            });
        });
        return stream;
    }
    extract(destination, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        this.createExtractJob(destination, options, (err, job, resp)=>{
            if (err) {
                callback(err, resp);
                return;
            }
            job.on('error', callback).on('complete', (metadata)=>{
                callback(null, metadata);
            });
        });
    }
    /**
     * Retrieves table data from a specified set of rows. The rows are returned to
     * your callback as an array of objects matching your table's schema.
     *
     * See {@link https://cloud.google.com/bigquery/docs/reference/v2/tabledata/list| Tabledata: list API Documentation}
     *
     * @param {object} [options] The configuration object.
     * @param {boolean} [options.autoPaginate=true] Have pagination handled
     *     automatically.
     * @param {number} [options.maxApiCalls] Maximum number of API calls to make.
     * @param {number} [options.maxResults] Maximum number of results to return.
     * @param {boolean|IntegerTypeCastOptions} [options.wrapIntegers=false] Wrap values
     *     of 'INT64' type in {@link BigQueryInt} objects.
     *     If a `boolean`, this will wrap values in {@link BigQueryInt} objects.
     *     If an `object`, this will return a value returned by
     *     `wrapIntegers.integerTypeCastFunction`.
     * @param {RowsCallback} [callback] The callback function. If `autoPaginate`
     *     is set to false a {@link ManualQueryResultsCallback} should be used.
     * @param {?error} callback.err An error returned while making this request
     * @param {array} callback.rows The table data from specified set of rows.
     * @returns {Promise<RowsResponse>}
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('my-dataset');
     * const table = dataset.table('my-table');
     *
     * table.getRows((err, rows) => {
     *   if (!err) {
     *     // rows is an array of results.
     *   }
     * });
     *
     * //-
     * // To control how many API requests are made and page through the results
     * // manually, set `autoPaginate` to `false`.
     * //-
     * function manualPaginationCallback(err, rows, nextQuery, apiResponse) {
     *   if (nextQuery) {
     *     // More results exist.
     *     table.getRows(nextQuery, manualPaginationCallback);
     *   }
     * }
     *
     * table.getRows({
     *   autoPaginate: false
     * }, manualPaginationCallback);
     *
     * //-
     * // If the callback is omitted, we'll return a Promise.
     * //-
     * table.getRows().then((data) => {
     *   const rows = data[0];
     *   });
     * ```
     */ getRows(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const wrapIntegers = options.wrapIntegers ? options.wrapIntegers : false;
        delete options.wrapIntegers;
        const parseJSON = options.parseJSON ? options.parseJSON : false;
        delete options.parseJSON;
        const selectedFields = options.selectedFields ? options.selectedFields.split(',') : [];
        const onComplete = (err, rows, nextQuery, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            rows = _1.BigQuery.mergeSchemaWithRows_(this.metadata.schema, rows || [], {
                wrapIntegers,
                selectedFields,
                parseJSON
            });
            callback(null, rows, nextQuery, resp);
        };
        const qs = extend({
            'formatOptions.useInt64Timestamp': true
        }, options);
        this.request({
            uri: '/data',
            qs
        }, (err, resp)=>{
            if (err) {
                onComplete(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.pageToken) {
                nextQuery = Object.assign({}, qs, {
                    pageToken: resp.pageToken
                });
            }
            if (resp.rows && resp.rows.length > 0 && !this.metadata.schema) {
                // We don't know the schema for this table yet. Do a quick stat.
                void this.getMetadata((err, metadata, apiResponse)=>{
                    if (err) {
                        onComplete(err, null, null, apiResponse);
                        return;
                    }
                    onComplete(null, resp.rows, nextQuery, resp);
                });
                return;
            }
            onComplete(null, resp.rows, nextQuery, resp);
        });
    }
    insert(rows, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const promise = this._insertAndCreateTable(rows, options);
        if (callback) {
            promise.then((resp)=>callback(null, resp), (err)=>callback(err, null));
        } else {
            return promise.then((r)=>[
                    r
                ]);
        }
    }
    /**
     * Insert rows with retries, but will create the table if not exists.
     *
     * @param {RowMetadata | RowMetadata[]} rows
     * @param {InsertRowsOptions} options
     * @returns {Promise<bigquery.ITableDataInsertAllResponse | bigquery.ITable>}
     * @private
     */ async _insertAndCreateTable(rows, options) {
        const { schema } = options;
        const delay = 60000;
        try {
            return await this._insertWithRetry(rows, options);
        } catch (err) {
            if (err.code !== 404 || !schema) {
                throw err;
            }
        }
        try {
            await this.create({
                schema
            });
        } catch (err) {
            if (err.code !== 409) {
                throw err;
            }
        }
        // table creation after failed access is subject to failure caching and
        // eventual consistency, see:
        // https://github.com/googleapis/google-cloud-python/issues/4553#issuecomment-350110292
        await new Promise((resolve)=>setTimeout(resolve, delay));
        return this._insertAndCreateTable(rows, options);
    }
    /**
     * This method will attempt to insert rows while retrying any partial failures
     * that occur along the way. Because partial insert failures are returned
     * differently, we can't depend on our usual retry strategy.
     *
     * @private
     *
     * @param {RowMetadata|RowMetadata[]} rows The rows to insert.
     * @param {InsertRowsOptions} options Insert options.
     * @returns {Promise<bigquery.ITableDataInsertAllResponse>}
     */ async _insertWithRetry(rows, options) {
        const { partialRetries = 3 } = options;
        let error;
        const maxAttempts = Math.max(partialRetries, 0) + 1;
        for(let attempts = 0; attempts < maxAttempts; attempts++){
            try {
                return await this._insert(rows, options);
            } catch (e) {
                error = e;
                rows = (e.errors || []).filter((err)=>!!err.row).map((err)=>err.row);
                if (!rows.length) {
                    break;
                }
            }
        }
        throw error;
    }
    /**
     * This method does the bulk of the work for processing options and making the
     * network request.
     *
     * @private
     *
     * @param {RowMetadata|RowMetadata[]} rows The rows to insert.
     * @param {InsertRowsOptions} options Insert options.
     * @returns {Promise<bigquery.ITableDataInsertAllResponse>}
     */ async _insert(rows, options) {
        rows = (0, util_1.toArray)(rows);
        if (!rows.length) {
            throw new Error('You must provide at least 1 row to be inserted.');
        }
        const json = extend(true, {}, options, {
            rows
        });
        if (!options.raw) {
            json.rows = rows.map((row)=>{
                const encoded = {
                    json: Table.encodeValue_(row)
                };
                if (options.createInsertId !== false) {
                    encoded.insertId = (0, crypto_1.randomUUID)();
                }
                return encoded;
            });
        }
        delete json.createInsertId;
        delete json.partialRetries;
        delete json.raw;
        delete json.schema;
        const [resp] = await this.request({
            method: 'POST',
            uri: '/insertAll',
            json
        });
        const partialFailures = (resp.insertErrors || []).map((insertError)=>{
            return {
                errors: insertError.errors.map((error)=>{
                    return {
                        message: error.message,
                        reason: error.reason
                    };
                }),
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                row: rows[insertError.index]
            };
        });
        if (partialFailures.length > 0) {
            throw new common_1.util.PartialFailureError({
                errors: partialFailures,
                response: resp
            });
        }
        return resp;
    }
    createInsertStream(options) {
        options = typeof options === 'object' ? options : {};
        const dup = new stream_1.Duplex({
            objectMode: true
        });
        dup._write = (chunk, encoding, cb)=>{
            this.rowQueue.add(chunk, ()=>{});
            cb();
        };
        this.rowQueue = new rowQueue_1.RowQueue(this, dup, options);
        return dup;
    }
    load(source, metadataOrCallback, cb) {
        const metadata = typeof metadataOrCallback === 'object' ? metadataOrCallback : {};
        const callback = typeof metadataOrCallback === 'function' ? metadataOrCallback : cb;
        this.createLoadJob(source, metadata, (err, job, resp)=>{
            if (err) {
                callback(err, resp);
                return;
            }
            job.on('error', callback).on('complete', (metadata)=>{
                callback(null, metadata);
            });
        });
    }
    query(query, callback) {
        if (typeof query === 'string') {
            query = {
                query
            };
        }
        this.dataset.query(query, callback);
    }
    setMetadata(metadata, callback) {
        const body = Table.formatMetadata_(metadata);
        void super.setMetadata(body, callback);
    }
    getIamPolicy(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        if (typeof options.requestedPolicyVersion === 'number' && options.requestedPolicyVersion !== 1) {
            throw new Error('Only IAM policy version 1 is supported.');
        }
        const json = extend(true, {}, {
            options
        });
        this.request({
            method: 'POST',
            uri: '/:getIamPolicy',
            json
        }, (err, resp)=>{
            if (err) {
                callback(err, null);
                return;
            }
            callback(null, resp);
        });
    }
    setIamPolicy(policy, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        if (policy.version && policy.version !== 1) {
            throw new Error('Only IAM policy version 1 is supported.');
        }
        const json = extend(true, {}, options, {
            policy
        });
        this.request({
            method: 'POST',
            uri: '/:setIamPolicy',
            json
        }, (err, resp)=>{
            if (err) {
                callback(err, null);
                return;
            }
            callback(null, resp);
        });
    }
    testIamPermissions(permissions, callback) {
        permissions = (0, util_1.toArray)(permissions);
        const json = extend(true, {}, {
            permissions
        });
        this.request({
            method: 'POST',
            uri: '/:testIamPermissions',
            json
        }, (err, resp)=>{
            if (err) {
                callback(err, null);
                return;
            }
            callback(null, resp);
        });
    }
}
exports.Table = Table;
/*! Developer Documentation
 *
 * These methods can be auto-paginated.
 */ paginator_1.paginator.extend(Table, [
    'getRows'
]);
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(Table); //# sourceMappingURL=table.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/model.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2019 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Model = void 0;
const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/util.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
/**
 * The model export formats accepted by BigQuery.
 *
 * @type {array}
 * @private
 */ const FORMATS = [
    'ML_TF_SAVED_MODEL',
    'ML_XGBOOST_BOOSTER'
];
/**
 * Model objects are returned by methods such as {@link Dataset#model} and
 * {@link Dataset#getModels}.
 *
 * @class
 * @param {Dataset} dataset {@link Dataset} instance.
 * @param {string} id The ID of the model.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 * const dataset = bigquery.dataset('my-dataset');
 *
 * const model = dataset.model('my-model');
 * ```
 */ class Model extends common_1.ServiceObject {
    dataset;
    bigQuery;
    constructor(dataset, id){
        const methods = {
            /**
             * @callback DeleteModelCallback
             * @param {?Error} err Request error, if any.
             * @param {object} apiResponse The full API response.
             */ /**
             * Delete the model.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/models/delete| Models: delete API Documentation}
             *
             * @method Model#delete
             * @param {DeleteModelCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const model = dataset.model('my-model');
             *
             * model.delete((err, apiResponse) => {});
             *
             * ```
             * @example If the callback is omitted we'll return a Promise.
             * ```
             * const [apiResponse] = await model.delete();
             * ```
             * @example If successful, the response body is empty.
             * ```
             * ```
             */ delete: true,
            /**
             * @callback ModelExistsCallback
             * @param {?Error} err Request error, if any.
             * @param {boolean} exists Indicates if the model exists.
             */ /**
             * @typedef {array} ModelExistsResponse
             * @property {boolean} 0 Indicates if the model exists.
             */ /**
             * Check if the model exists.
             *
             * @method Model#exists
             * @param {ModelExistsCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {boolean} callback.exists Whether the model exists or not.
             * @returns {Promise<ModelExistsResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const model = dataset.model('my-model');
             *
             * model.exists((err, exists) => {});
             *
             * ```
             * @example If the callback is omitted we'll return a Promise.
             * ```
             * const [exists] = await model.exists();
             * ```
             */ exists: true,
            /**
             * @callback GetModelCallback
             * @param {?Error} err Request error, if any.
             * @param {Model} model The model.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} GetModelResponse
             * @property {Model} 0 The model.
             * @property {object} 1 The full API response body.
             */ /**
             * Get a model if it exists.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/models/get| Models: get API Documentation}
             *
             * @method Model#get:
             * @param {GetModelCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Model} callback.model The {@link Model}.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetModelResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const model = dataset.model('my-model');
             *
             * model.get(err => {
             *   if (!err) {
             *     // `model.metadata` has been populated.
             *   }
             * });
             *
             * ```
             * @example If the callback is omitted we'll return a Promise.
             * ```
             * await model.get();
             * ```
             */ get: true,
            /**
             * @callback GetModelMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The model metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} GetModelMetadataResponse
             * @property {object} 0 The model metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Return the metadata associated with the model.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/models/get| Models: get API Documentation}
             *
             * @method Model#getMetadata
             * @param {GetModelMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.metadata The metadata of the model.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetModelMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const model = dataset.model('my-model');
             *
             * model.getMetadata((err, metadata, apiResponse) => {});
             *
             * ```
             * @example If the callback is omitted we'll return a Promise.
             * ```
             * const [metadata, apiResponse] = await model.getMetadata();
             * ```
             */ getMetadata: true,
            /**
             * @callback SetModelMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The model metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} SetModelMetadataResponse
             * @property {object} 0 The model metadata.
             * @property {object} 1 The full API response.
             */ /**
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/models/patch| Models: patch API Documentation}
             *
             * @method Model#setMetadata
             * @param {object} metadata The metadata key/value object to set.
             * @param {SetModelMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.metadata The updated metadata of the model.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<SetModelMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const model = dataset.model('my-model');
             *
             * const metadata = {
             *   friendlyName: 'TheBestModelEver'
             * };
             *
             * model.setMetadata(metadata, (err, metadata, apiResponse) => {});
             *
             * ```
             * @example If the callback is omitted we'll return a Promise.
             * ```
             * const [metadata, apiResponse] = await model.setMetadata(metadata);
             * ```
             */ setMetadata: true
        };
        super({
            parent: dataset,
            baseUrl: '/models',
            id,
            methods
        });
        this.dataset = dataset;
        this.bigQuery = dataset.bigQuery;
    }
    createExtractJob(destination, optionsOrCallback, cb) {
        let options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        options = extend(true, options, {
            destinationUris: (0, util_1.toArray)(destination).map((dest)=>{
                if (common_1.util.isCustomType(dest, 'storage/file')) {
                    return 'gs://' + dest.bucket.name + '/' + dest.name;
                }
                if (typeof dest === 'string') {
                    return dest;
                }
                throw new Error('Destination must be a string or a File object.');
            })
        });
        if (options.format) {
            options.format = options.format.toUpperCase();
            if (FORMATS.includes(options.format)) {
                options.destinationFormat = options.format;
                delete options.format;
            } else {
                throw new Error('Destination format not recognized: ' + options.format);
            }
        }
        const body = {
            configuration: {
                extract: extend(true, options, {
                    sourceModel: {
                        datasetId: this.dataset.id,
                        projectId: this.dataset.projectId,
                        modelId: this.id
                    }
                })
            }
        };
        if (options.jobPrefix) {
            body.jobPrefix = options.jobPrefix;
            delete options.jobPrefix;
        }
        if (options.jobId) {
            body.jobId = options.jobId;
            delete options.jobId;
        }
        if (body.configuration && options.reservation) {
            body.configuration.reservation = options.reservation;
            delete options.reservation;
        }
        this.bigQuery.createJob(body, callback);
    }
    extract(destination, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        this.createExtractJob(destination, options, (err, job, resp)=>{
            if (err) {
                callback(err, resp);
                return;
            }
            job.on('error', callback).on('complete', (metadata)=>{
                callback(null, metadata);
            });
        });
    }
}
exports.Model = Model;
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(Model); //# sourceMappingURL=model.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/routine.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Routine = void 0;
/*!
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
/**
 * Routine objects are returned by methods such as
 * {@link Dataset#routine}, {@link Dataset#createRoutine}, and
 * {@link Dataset#getRoutines}.
 *
 * @class
 * @param {Dataset} dataset {@link Dataset} instance.
 * @param {string} id The ID of the routine.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 * const dataset = bigquery.dataset('my-dataset');
 *
 * const routine = dataset.routine('my_routine');
 * ```
 */ class Routine extends common_1.ServiceObject {
    constructor(dataset, id){
        const methods = {
            /**
             * Create a routine.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/insert| Routines: insert API Documentation}
             *
             * @method Routine#create
             * @param {object} config A [routine resource]{@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#Routine}.
             * @param {CreateRoutineCallback} [callback] The callback function.
             * @returns {Promise<CreateRoutineResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * const config = {
             *   arguments: [{
             *     name: 'x',
             *     dataType: {
             *       typeKind: 'INT64'
             *     }
             *   }],
             *   definitionBody: 'x * 3',
             *   routineType: 'SCALAR_FUNCTION',
             *   returnType: {
             *     typeKind: 'INT64'
             *   }
             * };
             *
             * routine.create(config, (err, routine, apiResponse) => {
             *   if (!err) {
             *     // The routine was created successfully.
             *   }
             * });
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [routine, apiResponse] = await routine.create(config);
             * ```
             */ create: true,
            /**
             * @callback DeleteRoutineCallback
             * @param {?Error} err Request error, if any.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} DeleteRoutineResponse
             * @property {object} 0 The full API response.
             */ /**
             * Deletes a routine.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/delete| Routines: delete API Documentation}
             *
             * @method Routine#delete
             * @param {DeleteRoutineCallback} [callback] The callback function.
             * @returns {Promise<DeleteRoutineResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * routine.delete((err, apiResponse) => {
             *   if (!err) {
             *     // The routine was deleted successfully.
             *   }
             * });
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [apiResponse] = await routine.delete();
             * ```
             */ delete: true,
            /**
             * @callback RoutineExistsCallback
             * @param {?Error} err Request error, if any.
             * @param {boolean} exists Indicates if the routine exists.
             */ /**
             * @typedef {array} RoutineExistsResponse
             * @property {boolean} 0 Indicates if the routine exists.
             */ /**
             * Check if the routine exists.
             *
             * @method Routine#exists
             * @param {RoutineExistsCallback} [callback] The callback function.
             * @returns {Promise<RoutineExistsResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * routine.exists((err, exists) => {});
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [exists] = await routine.exists();
             * ```
             */ exists: true,
            /**
             * @callback GetRoutineCallback
             * @param {?Error} err Request error, if any.
             * @param {Routine} routine The routine.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} GetRoutineResponse
             * @property {Routine} 0 The routine.
             * @property {object} 1 The full API response body.
             */ /**
             * Get a routine if it exists.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/get| Routines: get API Documentation}
             *
             * @method Routine#get
             * @param {GetRoutineCallback} [callback] The callback function.
             * @returns {Promise<GetRoutineResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * routine.get((err, routine) => {});
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [routine2] = await routine.get();
             * ```
             */ get: true,
            /**
             * @callback GetRoutineMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The routine metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} GetRoutineMetadataResponse
             * @property {object} 0 The routine metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Get the metadata associated with a routine.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/get| Routines: get API Documentation}
             *
             * @method Routine#getMetadata
             * @param {GetRoutineMetadataCallback} [callback] The callback function.
             * @returns {Promise<GetRoutineMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * routine.getMetadata((err, metadata, apiResponse) => {});
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [metadata, apiResponse] = await routine.getMetadata();
             * ```
             */ getMetadata: true,
            /**
             * @callback SetRoutineMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The routine metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} SetRoutineMetadataResponse
             * @property {object} 0 The routine metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Update a routine.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/update| Routines: update API Documentation}
             *
             * @method Routine#setMetadata
             * @param {object} metadata A [routine resource object]{@link https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#Routine}.
             * @param {SetRoutineMetadataCallback} [callback] The callback function.
             * @returns {Promise<SetRoutineMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('my-dataset');
             * const routine = dataset.routine('my_routine');
             *
             * const updates = {
             *   description: 'The perfect description!'
             * };
             *
             * routine.setMetadata(updates, (err, metadata, apiResponse) => {});
             *
             * ```
             * @example If the callback is omitted a Promise will be returned
             * ```
             * const [metadata, apiResponse] = await routine.setMetadata(updates);
             * ```
             */ setMetadata: {
                reqOpts: {
                    method: 'PUT'
                }
            }
        };
        super({
            parent: dataset,
            baseUrl: '/routines',
            id,
            methods,
            createMethod: dataset.createRoutine.bind(dataset)
        });
    }
    setMetadata(metadata, callback) {
        // per the python client, it would appear that in order to update a routine
        // you need to send the routine in its entirety, not just the updated fields
        void this.getMetadata((err, fullMetadata)=>{
            if (err) {
                callback(err);
                return;
            }
            const updatedMetadata = extend(true, {}, fullMetadata, metadata);
            void super.setMetadata(updatedMetadata, callback);
        });
    }
}
exports.Routine = Routine;
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(Routine); //# sourceMappingURL=routine.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/dataset.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2014 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Dataset = void 0;
const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const paginator_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/paginator/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
const table_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/table.js [app-route] (ecmascript)");
const model_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/model.js [app-route] (ecmascript)");
const routine_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/routine.js [app-route] (ecmascript)");
/**
 * Interact with your BigQuery dataset. Create a Dataset instance with
 * {@link BigQuery#createDataset} or {@link BigQuery#dataset}.
 *
 * @class
 * @param {BigQuery} bigQuery {@link BigQuery} instance.
 * @param {string} id The ID of the Dataset.
 * @param {object} [options] Dataset options.
 * @param {string} [options.projectId] The GCP project ID.
 * @param {string} [options.location] The geographic location of the dataset.
 *      Defaults to US.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 * const dataset = bigquery.dataset('institutions');
 * ```
 */ class Dataset extends common_1.ServiceObject {
    bigQuery;
    location;
    projectId;
    getModelsStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    getRoutinesStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    getTablesStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    constructor(bigQuery, id, options){
        const methods = {
            /**
             * @callback CreateDatasetCallback
             * @param {?Error} err Request error, if any.
             * @param {Dataset} dataset The newly created dataset.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} CreateDatasetResponse
             * @property {Dataset} 0 The newly created dataset.
             * @property {object} 1 The full API response body.
             */ /**
             * Create a dataset.
             *
             * @method Dataset#create
             * @param {CreateDatasetCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Dataset} callback.dataset The newly created dataset.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<CreateDatasetResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('institutions');
             * dataset.create((err, dataset, apiResponse) => {
             *   if (!err) {
             *     // The dataset was created successfully.
             *   }
             * });
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * dataset.create().then((data) => {
             *   const dataset = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ create: true,
            /**
             * @callback DatasetExistsCallback
             * @param {?Error} err Request error, if any.
             * @param {boolean} exists Indicates if the dataset exists.
             */ /**
             * @typedef {array} DatasetExistsResponse
             * @property {boolean} 0 Indicates if the dataset exists.
             */ /**
             * Check if the dataset exists.
             *
             * @method Dataset#exists
             * @param {DatasetExistsCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {boolean} callback.exists Whether the dataset exists or not.
             * @returns {Promise<DatasetExistsResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('institutions');
             * dataset.exists((err, exists) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * dataset.exists().then((data) => {
             *   const exists = data[0];
             * });
             * ```
             */ exists: true,
            /**
             * @callback GetDatasetCallback
             * @param {?Error} err Request error, if any.
             * @param {Dataset} dataset The dataset.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} GetDatasetResponse
             * @property {Dataset} 0 The dataset.
             * @property {object} 1 The full API response body.
             */ /**
             * Get a dataset if it exists.
             *
             * You may optionally use this to "get or create" an object by providing
             * an object with `autoCreate` set to `true`. Any extra configuration that
             * is normally required for the `create` method must be contained within
             * this object as well.
             *
             * @method Dataset#get
             * @param {options} [options] Configuration object.
             * @param {boolean} [options.autoCreate=false] Automatically create the
             *     object if it does not exist.
             * @param {GetDatasetCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Dataset} callback.dataset The dataset.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetDatasetResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('institutions');
             * dataset.get((err, dataset, apiResponse) => {
             *   if (!err) {
             *     // `dataset.metadata` has been populated.
             *   }
             * });
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * dataset.get().then((data) => {
             *   const dataset = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ get: true,
            /**
             * @callback GetDatasetMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The dataset metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} GetDatasetMetadataResponse
             * @property {object} 0 The dataset metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Get the metadata for the Dataset.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/v2/datasets/get| Datasets: get API Documentation}
             *
             * @method Dataset#getMetadata
             * @param {GetDatasetMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.metadata The dataset's metadata.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetDatasetMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('institutions');
             * dataset.getMetadata((err, metadata, apiResponse) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * dataset.getMetadata().then((data) => {
             *   const metadata = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ getMetadata: true,
            /**
             * @callback SetDatasetMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} SetDatasetMetadataResponse
             * @property {object} 0 The full API response.
             */ /**
             * Sets the metadata of the Dataset object.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/v2/datasets/patch| Datasets: patch API Documentation}
             *
             * @method Dataset#setMetadata
             * @param {object} metadata Metadata to save on the Dataset.
             * @param {SetDatasetMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<SetDatasetMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             * const dataset = bigquery.dataset('institutions');
             *
             * const metadata = {
             *   description: 'Info for every institution in the 2013 IPEDS universe'
             * };
             *
             * dataset.setMetadata(metadata, (err, apiResponse) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * dataset.setMetadata(metadata).then((data) => {
             *   const apiResponse = data[0];
             * });
             * ```
             */ setMetadata: true
        };
        super({
            parent: bigQuery,
            baseUrl: '/datasets',
            id,
            methods,
            createMethod: (id, optionsOrCallback, cb)=>{
                let options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
                const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
                if (this.location) {
                    options = extend({}, options, {
                        location: this.location
                    });
                }
                if (this.projectId) {
                    options = extend({}, options, {
                        projectId: this.projectId
                    });
                }
                return bigQuery.createDataset(id, options, callback);
            }
        });
        if (options && options.location) {
            this.location = options.location;
        }
        if (options?.projectId) {
            this.projectId = options.projectId;
        } else {
            this.projectId = bigQuery.projectId;
        }
        this.bigQuery = bigQuery;
        // Catch all for read-modify-write cycle
        // https://cloud.google.com/bigquery/docs/api-performance#read-patch-write
        this.interceptors.push({
            request: (reqOpts)=>{
                if (reqOpts.method === 'PATCH' && reqOpts.json.etag) {
                    reqOpts.headers = reqOpts.headers || {};
                    reqOpts.headers['If-Match'] = reqOpts.json.etag;
                }
                if (this.projectId) {
                    // Override projectId if provided
                    reqOpts.uri = reqOpts.uri.replace(`/projects/${this.bigQuery.projectId}/`, `/projects/${this.projectId}/`);
                }
                return reqOpts;
            }
        });
        /**
         * List all or some of the {@link Model} objects in your project
         * as a readable object stream.
         *
         * @method Dataset#getModelsStream
         * @param {object} [options] Configuration object. See
         *     {@link Dataset#getModels} for a complete list of options.
         * @return {stream}
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         * const dataset = bigquery.dataset('institutions');
         *
         * dataset.getModelsStream()
         *   .on('error', console.error)
         *   .on('data', (model) => {})
         *   .on('end', () => {
         *     // All models have been retrieved
         *   });
         *
         * ```
         * @example If you anticipate many results, you can end a stream early to prevent unnecessary processing and API requests.
         * ```
         * dataset.getModelsStream()
         *   .on('data', function(model) {
         *     this.end();
         *   });
         * ```
         */ this.getModelsStream = paginator_1.paginator.streamify('getModels');
        /**
         * List all or some of the {@link Routine} objects in your project as a
         * readable object stream.
         *
         * @method Dataset#getRoutinesStream
         * @param {GetRoutinesOptions} [options] Configuration object.
         * @returns {stream}
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         * const dataset = bigquery.dataset('institutions');
         *
         * dataset.getRoutinesStream()
         *   .on('error', console.error)
         *   .on('data', (routine) => {})
         *   .on('end', () => {
         *     // All routines have been retrieved
         *   });
         *
         * ```
         * @example If you anticipate many results, you can end a stream early to prevent unnecessary processing and API requests.
         * ```
         * dataset.getRoutinesStream()
         *   .on('data', function(routine) {
         *     this.end();
         *   });
         * ```
         */ this.getRoutinesStream = paginator_1.paginator.streamify('getRoutines');
        /**
         * List all or some of the {@link Table} objects in your project
         * as a readable object stream.
         *
         * @method Dataset#getTablesStream
         * @param {object} [options] Configuration object. See
         *     {@link Dataset#getTables} for a complete list of options.
         * @return {stream}
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         * const dataset = bigquery.dataset('institutions');
         *
         * dataset.getTablesStream()
         *   .on('error', console.error)
         *   .on('data', (table) => {})
         *   .on('end', () => {
         *     // All tables have been retrieved
         *   });
         *
         * //-
         * // If you anticipate many results, you can end a stream early to prevent
         * // unnecessary processing and API requests.
         * //-
         * dataset.getTablesStream()
         *   .on('data', function(table) {
         *     this.end();
         *   });
         * ```
         */ this.getTablesStream = paginator_1.paginator.streamify('getTables');
    }
    createQueryJob(options, callback) {
        if (typeof options === 'string') {
            options = {
                query: options
            };
        }
        options = extend(true, {}, options, {
            defaultDataset: {
                datasetId: this.id
            },
            location: this.location
        });
        return this.bigQuery.createQueryJob(options, callback);
    }
    /**
     * Run a query scoped to your dataset as a readable object stream.
     *
     * See {@link BigQuery#createQueryStream} for full documentation of this
     * method.
     *
     * @param {object} options See {@link BigQuery#createQueryStream} for full
     *     documentation of this method.
     * @returns {stream}
     */ createQueryStream(options) {
        if (typeof options === 'string') {
            options = {
                query: options
            };
        }
        options = extend(true, {}, options, {
            defaultDataset: {
                datasetId: this.id
            },
            location: this.location
        });
        return this.bigQuery.createQueryStream(options);
    }
    createRoutine(id, config, callback) {
        const json = Object.assign({}, config, {
            routineReference: {
                routineId: id,
                datasetId: this.id,
                projectId: this.projectId
            }
        });
        this.request({
            method: 'POST',
            uri: '/routines',
            json
        }, (err, resp)=>{
            if (err) {
                callback(err, null, resp);
                return;
            }
            const routine = this.routine(resp.routineReference.routineId);
            routine.metadata = resp;
            callback(null, routine, resp);
        });
    }
    createTable(id, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const body = table_1.Table.formatMetadata_(options);
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        body.tableReference = {
            datasetId: this.id,
            projectId: this.projectId,
            tableId: id
        };
        this.request({
            method: 'POST',
            uri: '/tables',
            json: body
        }, (err, resp)=>{
            if (err) {
                callback(err, null, resp);
                return;
            }
            const table = this.table(resp.tableReference.tableId, {
                location: resp.location
            });
            table.metadata = resp;
            callback(null, table, resp);
        });
    }
    delete(optionsOrCallback, callback) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : callback;
        const query = {
            deleteContents: !!options.force
        };
        this.request({
            method: 'DELETE',
            uri: '',
            qs: query
        }, callback);
    }
    getModels(optsOrCb, cb) {
        const options = typeof optsOrCb === 'object' ? optsOrCb : {};
        const callback = typeof optsOrCb === 'function' ? optsOrCb : cb;
        this.request({
            uri: '/models',
            qs: options
        }, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.nextPageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.nextPageToken
                });
            }
            const models = (resp.models || []).map((modelObject)=>{
                const model = this.model(modelObject.modelReference.modelId);
                model.metadata = modelObject;
                return model;
            });
            callback(null, models, nextQuery, resp);
        });
    }
    getRoutines(optsOrCb, cb) {
        const options = typeof optsOrCb === 'object' ? optsOrCb : {};
        const callback = typeof optsOrCb === 'function' ? optsOrCb : cb;
        this.request({
            uri: '/routines',
            qs: options
        }, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.nextPageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.nextPageToken
                });
            }
            const routines = (resp.routines || []).map((metadata)=>{
                const routine = this.routine(metadata.routineReference.routineId);
                routine.metadata = metadata;
                return routine;
            });
            callback(null, routines, nextQuery, resp);
        });
    }
    getTables(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        this.request({
            uri: '/tables',
            qs: options
        }, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.nextPageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.nextPageToken
                });
            }
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const tables = (resp.tables || []).map((tableObject)=>{
                const table = this.table(tableObject.tableReference.tableId, {
                    location: tableObject.location
                });
                table.metadata = tableObject;
                return table;
            });
            callback(null, tables, nextQuery, resp);
        });
    }
    /**
     * Create a {@link Model} object.
     *
     * @throws {TypeError} if model ID is missing.
     *
     * @param {string} id The ID of the model.
     * @return {Model}
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('institutions');
     *
     * const model = dataset.model('my-model');
     * ```
     */ model(id) {
        if (typeof id !== 'string') {
            throw new TypeError('A model ID is required.');
        }
        return new model_1.Model(this, id);
    }
    query(options, callback) {
        if (typeof options === 'string') {
            options = {
                query: options
            };
        }
        options = extend(true, {}, options, {
            defaultDataset: {
                datasetId: this.id
            },
            location: this.location
        });
        return this.bigQuery.query(options, callback);
    }
    /**
     * Create a {@link Routine} object.
     *
     * @throws {TypeError} if routine ID is missing.
     *
     * @param {string} id The ID of the routine.
     * @returns {Routine}
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('institutions');
     *
     * const routine = dataset.routine('my_routine');
     * ```
     */ routine(id) {
        if (typeof id !== 'string') {
            throw new TypeError('A routine ID is required.');
        }
        return new routine_1.Routine(this, id);
    }
    /**
     * Create a {@link Table} object.
     *
     * @throws {TypeError} if table ID is missing.
     *
     * @param {string} id The ID of the table.
     * @param {object} [options] Table options.
     * @param {string} [options.location] The geographic location of the table, by
     *      default this value is inherited from the dataset. This can be used to
     *      configure the location of all jobs created through a table instance.
     * It cannot be used to set the actual location of the table. This value will
     *      be superseded by any API responses containing location data for the
     *      table.
     * @return {Table}
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('institutions');
     *
     * const institutions = dataset.table('institution_data');
     * ```
     */ table(id, options) {
        if (typeof id !== 'string') {
            throw new TypeError('A table ID is required.');
        }
        options = extend({
            location: this.location,
            projectId: this.projectId
        }, options);
        return new table_1.Table(this, id, options);
    }
}
exports.Dataset = Dataset;
/*! Developer Documentation
 *
 * These methods can be auto-paginated.
 */ paginator_1.paginator.extend(Dataset, [
    'getModels',
    'getRoutines',
    'getTables'
]);
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(Dataset, {
    exclude: [
        'model',
        'routine',
        'table'
    ]
}); //# sourceMappingURL=dataset.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/logger.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.logger = logger;
exports.setLogFunction = setLogFunction;
const util = __turbopack_context__.r("[externals]/util [external] (util, cjs)");
/*! The external function used to emit logs. */ let logFunction = null;
/**
 * Log function to use for debug output. By default, we don't perform any
 * logging.
 *
 * @private
 * @internal
 */ // eslint-disable-next-line @typescript-eslint/no-explicit-any
function logger(source, msg, ...otherArgs) {
    if (logFunction) {
        const time = new Date().toISOString();
        const formattedMsg = util.format(`D ${time} | ${source} | ${msg} |`, ...otherArgs);
        logFunction(formattedMsg);
    }
}
/**
 * Sets or disables the log function for all active BigQuery instances.
 *
 * @param logger A log function that takes a message (such as `console.log`) or
 * `null` to turn off logging.
 */ function setLogFunction(logger) {
    logFunction = logger;
} //# sourceMappingURL=logger.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/job.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2014 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Job = void 0;
/*!
 * @module bigquery/job
 */ const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const paginator_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/paginator/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
const bigquery_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/bigquery.js [app-route] (ecmascript)");
const logger_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/logger.js [app-route] (ecmascript)");
/**
 * @callback QueryResultsCallback
 * @param {?Error} err An error returned while making this request.
 * @param {array} rows The results of the job.
 */ /**
 * @callback ManualQueryResultsCallback
 * @param {?Error} err An error returned while making this request.
 * @param {array} rows The results of the job.
 * @param {?object} nextQuery A pre-made configuration object for your next
 *     request. This will be `null` if no additional results are available.
 *     If the query is not yet complete, you may get empty `rows` and
 *     non-`null` `nextQuery` that you should use for your next request.
 * @param {object} apiResponse The full API response.
 */ /**
 * Job objects are returned from various places in the BigQuery API:
 *
 * - {@link BigQuery#getJobs}
 * - {@link BigQuery#job}
 * - {@link BigQuery#query}
 * - {@link BigQuery#createJob}
 * - {@link Table#copy}
 * - {@link Table#createWriteStream}
 * - {@link Table#extract}
 * - {@link Table#load}
 *
 * They can be used to check the status of a running job or fetching the results
 * of a previously-executed one.
 *
 * @class
 * @param {BigQuery} bigQuery {@link BigQuery} instance.
 * @param {string} id The ID of the job.
 * @param {object} [options] Configuration object.
 * @param {string} [options.location] The geographic location of the job.
 *      Required except for US and EU.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 *
 * const job = bigquery.job('job-id');
 *
 * //-
 * // All jobs are event emitters. The status of each job is polled
 * // continuously, starting only after you register a "complete" listener.
 * //-
 * job.on('complete', (metadata) => {
 *   // The job is complete.
 * });
 *
 * //-
 * // Be sure to register an error handler as well to catch any issues which
 * // impeded the job.
 * //-
 * job.on('error', (err) => {
 *   // An error occurred during the job.
 * });
 *
 * //-
 * // To force the Job object to stop polling for updates, simply remove any
 * // "complete" listeners you've registered.
 * //
 * // The easiest way to do this is with `removeAllListeners()`.
 * //-
 * job.removeAllListeners();
 * ```
 */ class Job extends common_1.Operation {
    bigQuery;
    location;
    getQueryResultsStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    constructor(bigQuery, id, options){
        let location;
        const methods = {
            /**
             * @callback DeleteJobCallback
             * @param {?Error} err Request error, if any.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} DeleteJobResponse
             * @property {object} 0 The full API response.
             */ /**
             * Delete the job.
             *
             * @see [Jobs: delete API Documentation]{@link https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/delete}
             *
             * @method Job#delete
             * @param {DeleteJobCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<DeleteJobResponse>}
             *
             * @example
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             *
             * const job = bigquery.job(jobId);
             * job.delete((err, apiResponse) => {
             *   if (!err) {
             *     // The job was deleted successfully.
             *   }
             * });
             *
             * @example If the callback is omitted a Promise will be returned
             * const [apiResponse] = await job.delete();
             */ delete: {
                reqOpts: {
                    method: 'DELETE',
                    uri: '/delete',
                    qs: {
                        get location () {
                            return location;
                        }
                    }
                }
            },
            /**
             * @callback JobExistsCallback
             * @param {?Error} err Request error, if any.
             * @param {boolean} exists Indicates if the job exists.
             */ /**
             * @typedef {array} JobExistsResponse
             * @property {boolean} 0 Indicates if the job exists.
             */ /**
             * Check if the job exists.
             *
             * @method Job#exists
             * @param {JobExistsCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {boolean} callback.exists Whether the job exists or not.
             * @returns {Promise<JobExistsResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             *
             * const job = bigquery.job('job-id');
             *
             * job.exists((err, exists) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * job.exists().then((data) => {
             *   const exists = data[0];
             * });
             * ```
             */ exists: true,
            /**
             * @callback GetJobCallback
             * @param {?Error} err Request error, if any.
             * @param {Model} model The job.
             * @param {object} apiResponse The full API response body.
             */ /**
             * @typedef {array} GetJobResponse
             * @property {Model} 0 The job.
             * @property {object} 1 The full API response body.
             */ /**
             * Get a job if it exists.
             *
             * @method Job#get
             * @param {object} [options] Configuration object.
             * @param {string} [options.location] The geographic location of the job.
             *     Required except for US and EU.
             * @param {GetJobCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {Job} callback.job The job.
             * @returns {Promise<GetJobResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             *
             * const job = bigquery.job('job-id');
             *
             * job.get((err, job, apiResponse) => {
             *   if (!err) {
             *     // `job.metadata` has been populated.
             *   }
             * });
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * job.get().then((data) => {
             *   const job = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ get: true,
            /**
             * @callback GetJobMetadataCallback
             * @param {?Error} err Request error, if any.
             * @param {object} metadata The job metadata.
             * @param {object} apiResponse The full API response.
             */ /**
             * @typedef {array} GetJobMetadataResponse
             * @property {object} 0 The job metadata.
             * @property {object} 1 The full API response.
             */ /**
             * Get the metadata of the job. This will mostly be useful for checking
             * the status of a previously-run job.
             *
             * See {@link https://cloud.google.com/bigquery/docs/reference/v2/jobs/get| Jobs: get API Documentation}
             *
             * @method Job#getMetadata
             * @param {GetJobMetadataCallback} [callback] The callback function.
             * @param {?error} callback.err An error returned while making this
             *     request.
             * @param {object} callback.metadata The metadata of the job.
             * @param {object} callback.apiResponse The full API response.
             * @returns {Promise<GetJobMetadataResponse>}
             *
             * @example
             * ```
             * const {BigQuery} = require('@google-cloud/bigquery');
             * const bigquery = new BigQuery();
             *
             * const job = bigquery.job('id');
             * job.getMetadata((err, metadata, apiResponse) => {});
             *
             * //-
             * // If the callback is omitted, we'll return a Promise.
             * //-
             * job.getMetadata().then((data) => {
             *   const metadata = data[0];
             *   const apiResponse = data[1];
             * });
             * ```
             */ getMetadata: {
                reqOpts: {
                    qs: {
                        get location () {
                            return location;
                        }
                    }
                }
            }
        };
        super({
            parent: bigQuery,
            baseUrl: '/jobs',
            id,
            methods
        });
        Object.defineProperty(this, 'location', {
            get () {
                return location;
            },
            set (_location) {
                location = _location;
            }
        });
        this.bigQuery = bigQuery;
        if (options && options.location) {
            this.location = options.location;
        }
        if (options?.projectId) {
            this.projectId = options.projectId;
        }
        /**
         * Get the results of a job as a readable object stream.
         *
         * @param {object} options Configuration object. See
         *     {@link Job#getQueryResults} for a complete list of options.
         * @return {stream}
         *
         * @example
         * ```
         * const through2 = require('through2');
         * const fs = require('fs');
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         *
         * const job = bigquery.job('job-id');
         *
         * job.getQueryResultsStream()
         *   .pipe(through2.obj(function (row, enc, next) {
         *     this.push(JSON.stringify(row) + '\n');
         *     next();
         *   }))
         *   .pipe(fs.createWriteStream('./test/testdata/testfile.json'));
         * ```
         */ this.getQueryResultsStream = paginator_1.paginator.streamify('getQueryResultsAsStream_');
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    trace_(msg, ...otherArgs) {
        (0, logger_1.logger)(`[job][${this.id}]`, msg, ...otherArgs);
    }
    cancel(callback) {
        let qs;
        if (this.location) {
            qs = {
                location: this.location
            };
        }
        this.request({
            method: 'POST',
            uri: '/cancel',
            qs
        }, callback);
    }
    getQueryResults(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const qs = extend({
            location: this.location,
            'formatOptions.useInt64Timestamp': true
        }, options);
        this.trace_('[getQueryResults]', this.id, options.pageToken, options.startIndex);
        const wrapIntegers = qs.wrapIntegers ? qs.wrapIntegers : false;
        delete qs.wrapIntegers;
        const parseJSON = qs.parseJSON ? qs.parseJSON : false;
        delete qs.parseJSON;
        delete qs.job;
        const timeoutOverride = typeof qs.timeoutMs === 'number' ? qs.timeoutMs : false;
        const cachedRows = options._cachedRows;
        const cachedResponse = options._cachedResponse;
        delete options._cachedRows;
        delete options._cachedResponse;
        if (cachedRows) {
            let nextQuery = null;
            if (options.pageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: options.pageToken
                });
            }
            delete cachedResponse?.rows;
            callback(null, cachedRows, nextQuery, cachedResponse);
            return;
        }
        this.bigQuery.request({
            uri: '/queries/' + this.id,
            qs
        }, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            let rows = [];
            if (resp.schema && resp.rows) {
                rows = bigquery_1.BigQuery.mergeSchemaWithRows_(resp.schema, resp.rows, {
                    wrapIntegers,
                    parseJSON
                });
            }
            let nextQuery = null;
            if (resp.jobComplete === false) {
                // Query is still running.
                nextQuery = Object.assign({}, options);
                // If timeout override was provided, return error.
                if (timeoutOverride) {
                    const err = new Error(`The query did not complete before ${timeoutOverride}ms`);
                    callback(err, null, nextQuery, resp);
                    return;
                }
            } else if (resp.pageToken) {
                this.trace_('[getQueryResults] has more pages', resp.pageToken);
                // More results exist.
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.pageToken
                });
                delete nextQuery.startIndex;
            }
            delete resp.rows;
            callback(null, rows, nextQuery, resp);
        });
    }
    /**
     * This method will be called by `getQueryResultsStream()`. It is required to
     * properly set the `autoPaginate` option value.
     *
     * @private
     */ getQueryResultsAsStream_(options, callback) {
        options = extend({
            autoPaginate: false
        }, options);
        this.getQueryResults(options, callback);
    }
    /**
     * Poll for a status update. Execute the callback:
     *
     *   - callback(err): Job failed
     *   - callback(): Job incomplete
     *   - callback(null, metadata): Job complete
     *
     * @private
     *
     * @param {function} callback
     */ poll_(callback) {
        void this.getMetadata((err, metadata)=>{
            if (!err && metadata.status && metadata.status.errorResult) {
                err = new common_1.util.ApiError(metadata.status);
            }
            if (err) {
                callback(err);
                return;
            }
            if (metadata.status.state !== 'DONE') {
                callback(null);
                return;
            }
            callback(null, metadata);
        });
    }
}
exports.Job = Job;
/*! Developer Documentation
 *
 * These methods can be auto-paginated.
 */ paginator_1.paginator.extend(Job, [
    'getQueryResults'
]);
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(Job); //# sourceMappingURL=job.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/package.json (json)", ((__turbopack_context__) => {

__turbopack_context__.v({"name":"@google-cloud/bigquery","description":"Google BigQuery Client Library for Node.js","version":"8.1.1","license":"Apache-2.0","author":"Google LLC","engines":{"node":">=18"},"repository":"googleapis/nodejs-bigquery","main":"./build/src/index.js","types":"./build/src/index.d.ts","files":["build/src","!build/src/**/*.map"],"keywords":["google apis client","google api client","google apis","google api","google","google cloud platform","google cloud","cloud","google bigquery","bigquery"],"scripts":{"prebenchmark":"npm run compile","benchmark":"node build/benchmark/bench.js benchmark/queries.json","docs":"jsdoc -c .jsdoc.js","lint":"gts check","samples-test":"cd samples/ && npm link ../ && npm test && cd ../","test":"c8 mocha build/test","system-test":"mocha build/system-test --timeout 600000","presystem-test":"npm run compile","clean":"gts clean","compile":"tsc -p . && cp src/types.d.ts build/src/","fix":"gts fix","predocs":"npm run compile","prepare":"npm run compile","pretest":"npm run compile","docs-test":"linkinator docs","predocs-test":"npm run docs","types":"node scripts/gen-types.js","prelint":"cd samples; npm link ../; npm install","precompile":"gts clean"},"dependencies":{"@google-cloud/common":"^6.0.0","@google-cloud/paginator":"^6.0.0","@google-cloud/precise-date":"^5.0.0","@google-cloud/promisify":"^5.0.0","teeny-request":"^10.0.0","arrify":"^3.0.0","big.js":"^6.2.2","duplexify":"^4.1.3","extend":"^3.0.2","stream-events":"^1.0.5"},"overrides":{"@google-cloud/common":{"google-auth-library":"10.1.0"}},"devDependencies":{"@google-cloud/storage":"^7.16.0","@types/big.js":"^6.2.2","@types/duplexify":"^3.6.4","@types/extend":"^3.0.4","@types/is":"^0.0.25","@types/mocha":"^10.0.10","@types/node":"^22.14.0","@types/proxyquire":"^1.3.31","@types/sinon":"^17.0.4","c8":"^10.1.3","codecov":"^3.8.3","discovery-tsd":"^0.3.0","eslint-plugin-prettier":"^5.2.6","gts":"^6.0.2","jsdoc":"^4.0.4","jsdoc-fresh":"^3.0.0","jsdoc-region-tag":"^3.0.0","linkinator":"^6.1.2","mocha":"^11.1.0","nise":"^6.1.1","pack-n-play":"^3.0.1","path-to-regexp":"^8.2.0","prettier":"^3.5.3","proxyquire":"^2.1.3","sinon":"^20.0.0","typescript":"^5.8.2"}});}),
"[project]/node_modules/@google-cloud/bigquery/build/src/bigquery.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.BigQueryInt = exports.BigQueryTime = exports.BigQueryDatetime = exports.BigQueryTimestamp = exports.Geography = exports.BigQueryDate = exports.BigQueryRange = exports.BigQuery = exports.PROTOCOL_REGEX = exports.common = void 0;
const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
const common = __turbopack_context__.r("[project]/node_modules/@google-cloud/common/build/src/index.js [app-route] (ecmascript)");
exports.common = common;
const paginator_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/paginator/build/src/index.js [app-route] (ecmascript)");
const promisify_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/promisify/build/src/index.js [app-route] (ecmascript)");
const precise_date_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/precise-date/build/src/index.js [app-route] (ecmascript)");
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/util.js [app-route] (ecmascript)");
const Big = __turbopack_context__.r("[project]/node_modules/big.js/big.js [app-route] (ecmascript)");
const extend = __turbopack_context__.r("[project]/node_modules/extend/index.js [app-route] (ecmascript)");
const crypto_1 = __turbopack_context__.r("[externals]/crypto [external] (crypto, cjs)");
const dataset_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/dataset.js [app-route] (ecmascript)");
const job_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/job.js [app-route] (ecmascript)");
const table_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/table.js [app-route] (ecmascript)");
const logger_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/logger.js [app-route] (ecmascript)");
exports.PROTOCOL_REGEX = /^(\w*):\/\//;
/**
 * @typedef {object} BigQueryOptions
 * @property {string} [projectId] The project ID from the Google Developer's
 *     Console, e.g. 'grape-spaceship-123'. We will also check the environment
 *     variable `GCLOUD_PROJECT` for your project ID. If your app is running in
 *     an environment which supports {@link
 * https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application
 * Application Default Credentials}, your project ID will be detected
 * automatically.
 * @property {string} [keyFilename] Full path to the a .json, .pem, or .p12 key
 *     downloaded from the Google Developers Console. If you provide a path to a
 *     JSON file, the `projectId` option above is not necessary. NOTE: .pem and
 *     .p12 require you to specify the `email` option as well.
 * @property {string} [token] An OAUTH access token. If provided, we will not
 *     manage fetching, re-using, and re-minting access tokens.
 * @property {string} [email] Account email address. Required when using a .pem
 *     or .p12 keyFilename.
 * @property {object} [credentials] Credentials object.
 * @property {string} [credentials.client_email]
 * @property {string} [credentials.private_key]
 * @property {Constructor} [promise] Custom promise module to use instead of
 *     native Promises.
 * @property {string[]} [scopes] Additional OAuth scopes to use in requests. For
 *     example, to access an external data source, you may need the
 *     `https://www.googleapis.com/auth/drive.readonly` scope.
 */ /**
 * In the following examples from this page and the other modules (`Dataset`,
 * `Table`, etc.), we are going to be using a dataset from
 * {@link http://goo.gl/f2SXcb| data.gov} of higher education institutions.
 *
 * We will create a table with the correct schema, import the public CSV file
 * into that table, and query it for data.
 *
 * @class
 *
 * See {@link https://cloud.google.com/bigquery/what-is-bigquery| What is BigQuery?}
 *
 * @param {BigQueryOptions} options Constructor options.
 *
 * @example Install the client library with <a href="https://www.npmjs.com/">npm</a>:
 * ```
 * npm install @google-cloud/bigquery
 *
 * ```
 * @example Import the client library
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 *
 * ```
 * @example Create a client that uses <a href="https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application">Application Default Credentials (ADC)</a>:
 * ```
 * const bigquery = new BigQuery();
 *
 * ```
 * @example Create a client with <a href="https://cloud.google.com/docs/authentication/production#obtaining_and_providing_service_account_credentials_manually">explicit credentials</a>:
 * ```
 * const bigquery = new BigQuery({
 *   projectId: 'your-project-id',
 *   keyFilename: '/path/to/keyfile.json'
 * });
 *
 * ```
 * @example <caption>include:samples/quickstart.js</caption>
 * region_tag:bigquery_quickstart
 * Full quickstart example:
 */ class BigQuery extends common_1.Service {
    location;
    _universeDomain;
    _defaultJobCreationMode;
    createQueryStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    getDatasetsStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    getJobsStream(options) {
        // placeholder body, overwritten in constructor
        return new paginator_1.ResourceStream({}, ()=>{});
    }
    constructor(options = {}){
        let universeDomain = 'googleapis.com';
        const servicePath = 'bigquery';
        if (options.universeDomain) {
            universeDomain = BigQuery.sanitizeDomain(options.universeDomain);
        }
        const EMULATOR_HOST = process.env.BIGQUERY_EMULATOR_HOST;
        let apiEndpoint = `https://${servicePath}.${universeDomain}`;
        if (typeof EMULATOR_HOST === 'string') {
            apiEndpoint = BigQuery.sanitizeEndpoint(EMULATOR_HOST);
        }
        if (options.apiEndpoint) {
            apiEndpoint = BigQuery.sanitizeEndpoint(options.apiEndpoint);
        }
        options = Object.assign({}, options, {
            apiEndpoint
        });
        const baseUrl = EMULATOR_HOST || `${options.apiEndpoint}/bigquery/v2`;
        const config = {
            apiEndpoint: options.apiEndpoint,
            baseUrl,
            scopes: [
                'https://www.googleapis.com/auth/bigquery'
            ],
            packageJson: __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/package.json (json)"),
            autoRetry: options.autoRetry,
            maxRetries: options.maxRetries,
            retryOptions: options.retryOptions
        };
        if (options.scopes) {
            config.scopes = config.scopes.concat(options.scopes);
        }
        super(config, options);
        if (options.defaultJobCreationMode) {
            this._defaultJobCreationMode = options.defaultJobCreationMode;
        }
        this._universeDomain = universeDomain;
        this.location = options.location;
        /**
         * Run a query scoped to your project as a readable object stream.
         *
         * @method
         * @param {object} query Configuration object. See {@link BigQuery.query} for a complete
         *     list of options.
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         *
         * const query = 'SELECT url FROM `publicdata.samples.github_nested` LIMIT
         * 100';
         *
         * bigquery.createQueryStream(query)
         *   .on('error', console.error)
         *   .on('data', function(row) {
         *     // row is a result from your query.
         *   })
         *   .on('end', function() {
         *     // All rows retrieved.
         *   });
         *
         * //-
         * // If you anticipate many results, you can end a stream early to prevent
         * // unnecessary processing and API requests.
         * //-
         * bigquery.createQueryStream(query)
         *   .on('data', function(row) {
         *     this.end();
         *   });
         * ```
         */ this.createQueryStream = paginator_1.paginator.streamify('queryAsStream_');
        /**
         * List all or some of the {@link Dataset} objects in your project as
         * a readable object stream.
         *
         * @param {object} [options] Configuration object. See
         *     {@link BigQuery.getDatasets} for a complete list of options.
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         *
         * bigquery.getDatasetsStream()
         *   .on('error', console.error)
         *   .on('data', function(dataset) {
         *     // dataset is a Dataset object.
         *   })
         *   .on('end', function() {
         *     // All datasets retrieved.
         *   });
         *
         * //-
         * // If you anticipate many results, you can end a stream early to prevent
         * // unnecessary processing and API requests.
         * //-
         * bigquery.getDatasetsStream()
         *   .on('data', function(dataset) {
         *     this.end();
         *   });
         * ```
         */ this.getDatasetsStream = paginator_1.paginator.streamify('getDatasets');
        /**
         * List all or some of the {@link Job} objects in your project as a
         * readable object stream.
         *
         * @param {object} [options] Configuration object. See
         *     {@link BigQuery.getJobs} for a complete list of options.
         *
         * @example
         * ```
         * const {BigQuery} = require('@google-cloud/bigquery');
         * const bigquery = new BigQuery();
         *
         * bigquery.getJobsStream()
         *   .on('error', console.error)
         *   .on('data', function(job) {
         *     // job is a Job object.
         *   })
         *   .on('end', function() {
         *     // All jobs retrieved.
         *   });
         *
         * //-
         * // If you anticipate many results, you can end a stream early to prevent
         * // unnecessary processing and API requests.
         * //-
         * bigquery.getJobsStream()
         *   .on('data', function(job) {
         *     this.end();
         *   });
         * ```
         */ this.getJobsStream = paginator_1.paginator.streamify('getJobs');
        // Disable `prettyPrint` for better performance.
        // https://github.com/googleapis/nodejs-bigquery/issues/858
        this.interceptors.push({
            request: (reqOpts)=>{
                return extend(true, {}, reqOpts, {
                    qs: {
                        prettyPrint: false
                    }
                });
            }
        });
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    trace_(msg, ...otherArgs) {
        (0, logger_1.logger)('[bigquery]', msg, ...otherArgs);
    }
    get universeDomain() {
        return this._universeDomain;
    }
    static sanitizeEndpoint(url) {
        if (!exports.PROTOCOL_REGEX.test(url)) {
            url = `https://${url}`;
        }
        return this.sanitizeDomain(url);
    }
    static sanitizeDomain(url) {
        return url.replace(/\/+$/, ''); // Remove trailing slashes
    }
    /**
     * Merge a rowset returned from the API with a table schema.
     *
     * @private
     *
     * @param {object} schema
     * @param {array} rows
     * @param {object} options
     * @param {boolean|IntegerTypeCastOptions} options.wrapIntegers Wrap values of
     *     'INT64' type in {@link BigQueryInt} objects.
     *     If a `boolean`, this will wrap values in {@link BigQueryInt} objects.
     *     If an `object`, this will return a value returned by
     *     `wrapIntegers.integerTypeCastFunction`.
     *     Please see {@link IntegerTypeCastOptions} for options descriptions.
     * @param {array} options.selectedFields List of fields to return.
     * If unspecified, all fields are returned.
     * @param {array} options.parseJSON parse a 'JSON' field into a JSON object.
     * @returns Fields using their matching names from the table's schema.
     */ static mergeSchemaWithRows_(schema, rows, options) {
        // deep copy schema fields to avoid mutation
        let schemaFields = extend(true, [], schema?.fields);
        let selectedFields = extend(true, [], options.selectedFields);
        if (options.selectedFields && options.selectedFields.length > 0) {
            const selectedFieldsArray = options.selectedFields.map((c)=>{
                return c.split('.');
            });
            const currentFields = selectedFieldsArray.map((c)=>c.shift()).filter((c)=>c !== undefined);
            //filter schema fields based on selected fields.
            schemaFields = schemaFields.filter((field)=>currentFields.map((c)=>c.toLowerCase()).indexOf(field.name.toLowerCase()) >= 0);
            selectedFields = selectedFieldsArray.filter((c)=>c.length > 0).map((c)=>c.join('.'));
        }
        return (0, util_1.toArray)(rows).map(mergeSchema).map(flattenRows);
        //TURBOPACK unreachable
        ;
        function mergeSchema(row) {
            return row.f.map((field, index)=>{
                const schemaField = schemaFields[index];
                let value = field.v;
                if (schemaField && schemaField.mode === 'REPEATED') {
                    value = value.map((val)=>{
                        return convertSchemaFieldValue(schemaField, val.v, {
                            ...options,
                            selectedFields
                        });
                    });
                } else {
                    value = convertSchemaFieldValue(schemaField, value, {
                        ...options,
                        selectedFields
                    });
                }
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                const fieldObject = {};
                fieldObject[schemaField.name] = value;
                return fieldObject;
            });
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function flattenRows(rows) {
            return rows.reduce((acc, row)=>{
                const key = Object.keys(row)[0];
                acc[key] = row[key];
                return acc;
            }, {});
        }
    }
    /**
     * The `DATE` type represents a logical calendar date, independent of time
     * zone. It does not represent a specific 24-hour time period. Rather, a given
     * DATE value represents a different 24-hour period when interpreted in
     * different time zones, and may represent a shorter or longer day during
     * Daylight Savings Time transitions.
     *
     * @param {object|string} value The date. If a string, this should be in the
     *     format the API describes: `YYYY-[M]M-[D]D`.
     *     Otherwise, provide an object.
     * @param {string|number} value.year Four digits.
     * @param {string|number} value.month One or two digits.
     * @param {string|number} value.day One or two digits.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const date = bigquery.date('2017-01-01');
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const date2 = bigquery.date({
     *   year: 2017,
     *   month: 1,
     *   day: 1
     * });
     * ```
     */ static date(value) {
        return new BigQueryDate(value);
    }
    /**
     * @param {object|string} value The date. If a string, this should be in the
     *     format the API describes: `YYYY-[M]M-[D]D`.
     *     Otherwise, provide an object.
     * @param {string|number} value.year Four digits.
     * @param {string|number} value.month One or two digits.
     * @param {string|number} value.day One or two digits.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const date = BigQuery.date('2017-01-01');
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const date2 = BigQuery.date({
     *   year: 2017,
     *   month: 1,
     *   day: 1
     * });
     * ```
     */ date(value) {
        return BigQuery.date(value);
    }
    /**
     * A `DATETIME` data type represents a point in time. Unlike a `TIMESTAMP`,
     * this does not refer to an absolute instance in time. Instead, it is the
     * civil time, or the time that a user would see on a watch or calendar.
     *
     * @method BigQuery.datetime
     * @param {object|string} value The time. If a string, this should be in the
     *     format the API describes: `YYYY-[M]M-[D]D[ [H]H:[M]M:[S]S[.DDDDDD]]`.
     *     Otherwise, provide an object.
     * @param {string|number} value.year Four digits.
     * @param {string|number} value.month One or two digits.
     * @param {string|number} value.day One or two digits.
     * @param {string|number} [value.hours] One or two digits (`00` - `23`).
     * @param {string|number} [value.minutes] One or two digits (`00` - `59`).
     * @param {string|number} [value.seconds] One or two digits (`00` - `59`).
     * @param {string|number} [value.fractional] Up to six digits for microsecond
     *     precision.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const datetime = BigQuery.datetime('2017-01-01 13:00:00');
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const datetime = BigQuery.datetime({
     *   year: 2017,
     *   month: 1,
     *   day: 1,
     *   hours: 14,
     *   minutes: 0,
     *   seconds: 0
     * });
     * ```
     */ /**
     * A `DATETIME` data type represents a point in time. Unlike a `TIMESTAMP`,
     * this does not refer to an absolute instance in time. Instead, it is the
     * civil time, or the time that a user would see on a watch or calendar.
     *
     * @param {object|string} value The time. If a string, this should be in the
     *     format the API describes: `YYYY-[M]M-[D]D[ [H]H:[M]M:[S]S[.DDDDDD]]`.
     *     Otherwise, provide an object.
     * @param {string|number} value.year Four digits.
     * @param {string|number} value.month One or two digits.
     * @param {string|number} value.day One or two digits.
     * @param {string|number} [value.hours] One or two digits (`00` - `23`).
     * @param {string|number} [value.minutes] One or two digits (`00` - `59`).
     * @param {string|number} [value.seconds] One or two digits (`00` - `59`).
     * @param {string|number} [value.fractional] Up to six digits for microsecond
     *     precision.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const datetime = bigquery.datetime('2017-01-01 13:00:00');
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const datetime = bigquery.datetime({
     *   year: 2017,
     *   month: 1,
     *   day: 1,
     *   hours: 14,
     *   minutes: 0,
     *   seconds: 0
     * });
     * ```
     */ static datetime(value) {
        return new BigQueryDatetime(value);
    }
    datetime(value) {
        return BigQuery.datetime(value);
    }
    /**
     * A `TIME` data type represents a time, independent of a specific date.
     *
     * @method BigQuery.time
     * @param {object|string} value The time. If a string, this should be in the
     *     format the API describes: `[H]H:[M]M:[S]S[.DDDDDD]`. Otherwise, provide
     *     an object.
     * @param {string|number} [value.hours] One or two digits (`00` - `23`).
     * @param {string|number} [value.minutes] One or two digits (`00` - `59`).
     * @param {string|number} [value.seconds] One or two digits (`00` - `59`).
     * @param {string|number} [value.fractional] Up to six digits for microsecond
     *     precision.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const time = BigQuery.time('14:00:00'); // 2:00 PM
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const time = BigQuery.time({
     *   hours: 14,
     *   minutes: 0,
     *   seconds: 0
     * });
     * ```
     */ /**
     * A `TIME` data type represents a time, independent of a specific date.
     *
     * @param {object|string} value The time. If a string, this should be in the
     *     format the API describes: `[H]H:[M]M:[S]S[.DDDDDD]`. Otherwise, provide
     *     an object.
     * @param {string|number} [value.hours] One or two digits (`00` - `23`).
     * @param {string|number} [value.minutes] One or two digits (`00` - `59`).
     * @param {string|number} [value.seconds] One or two digits (`00` - `59`).
     * @param {string|number} [value.fractional] Up to six digits for microsecond
     *     precision.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const time = bigquery.time('14:00:00'); // 2:00 PM
     *
     * //-
     * // Alternatively, provide an object.
     * //-
     * const time = bigquery.time({
     *   hours: 14,
     *   minutes: 0,
     *   seconds: 0
     * });
     * ```
     */ static time(value) {
        return new BigQueryTime(value);
    }
    time(value) {
        return BigQuery.time(value);
    }
    /**
     * A timestamp represents an absolute point in time, independent of any time
     * zone or convention such as Daylight Savings Time.
     *
     * The recommended input here is a `Date` or `PreciseDate` class.
     * If passing as a `string`, it should be Timestamp literals: https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#timestamp_literals.
     * When passing a `number` input, it should be epoch seconds in float representation.
     *
     * @method BigQuery.timestamp
     * @param {Date|string} value The time.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const timestamp = BigQuery.timestamp(new Date());
     * ```
     */ static timestamp(value) {
        return new BigQueryTimestamp(value);
    }
    /**
     * A timestamp represents an absolute point in time, independent of any time
     * zone or convention such as Daylight Savings Time.
     *
     * The recommended input here is a `Date` or `PreciseDate` class.
     * If passing as a `string`, it should be Timestamp literals: https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#timestamp_literals.
     * When passing a `number` input, it should be epoch seconds in float representation.
     *
     * @param {Date|string|string|number} value The time.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const timestamp = bigquery.timestamp(new Date());
     * ```
     */ timestamp(value) {
        return BigQuery.timestamp(value);
    }
    /**
     * A range represents contiguous range between two dates, datetimes, or timestamps.
     * The lower and upper bound for the range are optional.
     * The lower bound is inclusive and the upper bound is exclusive.
     *
     * @method BigQuery.range
     * @param {string|BigQueryRangeOptions} value The range API string or start/end with dates/datetimes/timestamp ranges.
     * @param {string} elementType The range element type - DATE|DATETIME|TIMESTAMP
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const timestampRange = BigQuery.range('[2020-10-01 12:00:00+08, 2020-12-31 12:00:00+08)', 'TIMESTAMP');
     * ```
     */ static range(value, elementType) {
        return new BigQueryRange(value, elementType);
    }
    /**
     * A range represents contiguous range between two dates, datetimes, or timestamps.
     * The lower and upper bound for the range are optional.
     * The lower bound is inclusive and the upper bound is exclusive.
     *
     * @param {string|BigQueryRangeOptions} value The range API string or start/end with dates/datetimes/timestamp ranges.
     * @param {string} elementType The range element type - DATE|DATETIME|TIMESTAMP
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const timestampRange = bigquery.range('[2020-10-01 12:00:00+08, 2020-12-31 12:00:00+08)', 'TIMESTAMP');
     * ```
     */ range(value, elementType) {
        return BigQuery.range(value, elementType);
    }
    /**
     * A BigQueryInt wraps 'INT64' values. Can be used to maintain precision.
     *
     * @param {string|number|IntegerTypeCastValue} value The INT64 value to convert.
     * @param {IntegerTypeCastOptions} typeCastOptions Configuration to convert
     *     value. Must provide an `integerTypeCastFunction` to handle conversion.
     * @returns {BigQueryInt}
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     *
     * const largeIntegerValue = Number.MAX_SAFE_INTEGER + 1;
     *
     * const options = {
     *   integerTypeCastFunction: value => value.split(),
     * };
     *
     * const bqInteger = bigquery.int(largeIntegerValue, options);
     *
     * const customValue = bqInteger.valueOf();
     * // customValue is the value returned from your `integerTypeCastFunction`.
     * ```
     */ static int(value, typeCastOptions) {
        return new BigQueryInt(value, typeCastOptions);
    }
    int(value, typeCastOptions) {
        return BigQuery.int(value, typeCastOptions);
    }
    /**
     * A geography value represents a surface area on the Earth
     * in Well-known Text (WKT) format.
     *
     * @param {string} value The geospatial data.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const geography = bigquery.geography('POINT(1, 2)');
     * ```
     */ static geography(value) {
        return new Geography(value);
    }
    geography(value) {
        return BigQuery.geography(value);
    }
    /**
     * Convert an INT64 value to Number.
     *
     * @private
     * @param {object} value The INT64 value to convert.
     */ static decodeIntegerValue_(value) {
        const num = Number(value.integerValue);
        if (!Number.isSafeInteger(num)) {
            throw new Error('We attempted to return all of the numeric values, but ' + (value.schemaFieldName ? value.schemaFieldName + ' ' : '') + 'value ' + value.integerValue + " is out of bounds of 'Number.MAX_SAFE_INTEGER'.\n" + "To prevent this error, please consider passing 'options.wrapIntegers' as\n" + '{\n' + '  integerTypeCastFunction: provide <your_custom_function>\n' + '  fields: optionally specify field name(s) to be custom casted\n' + '}\n');
        }
        return num;
    }
    /**
     * Return a value's provided type.
     *
     * @private
     *
     * @throws {error} If the type provided is invalid.
     *
     * See {@link https://cloud.google.com/bigquery/data-types| Data Type}
     *
     * @param {*} providedType The type.
     * @returns {string} The valid type provided.
     */ static getTypeDescriptorFromProvidedType_(providedType) {
        // The list of types can be found in src/types.d.ts
        const VALID_TYPES = [
            'DATE',
            'DATETIME',
            'TIME',
            'TIMESTAMP',
            'BYTES',
            'NUMERIC',
            'DECIMAL',
            'BIGNUMERIC',
            'BIGDECIMAL',
            'BOOL',
            'INT64',
            'INT',
            'SMALLINT',
            'INTEGER',
            'BIGINT',
            'TINYINT',
            'BYTEINT',
            'FLOAT64',
            'FLOAT',
            'STRING',
            'GEOGRAPHY',
            'ARRAY',
            'STRUCT',
            'JSON',
            'RANGE'
        ];
        if ((0, util_1.isArray)(providedType)) {
            providedType = providedType;
            return {
                type: 'ARRAY',
                arrayType: BigQuery.getTypeDescriptorFromProvidedType_(providedType[0])
            };
        } else if ((0, util_1.isObject)(providedType)) {
            return {
                type: 'STRUCT',
                structTypes: Object.keys(providedType).map((prop)=>{
                    return {
                        name: prop,
                        type: BigQuery.getTypeDescriptorFromProvidedType_(providedType[prop])
                    };
                })
            };
        }
        providedType = providedType.toUpperCase();
        if (!VALID_TYPES.includes(providedType)) {
            throw new Error(`Invalid type provided: "${providedType}"`);
        }
        return {
            type: providedType.toUpperCase()
        };
    }
    /**
     * Detect a value's type.
     *
     * @private
     *
     * @throws {error} If the type could not be detected.
     *
     * See {@link https://cloud.google.com/bigquery/data-types| Data Type}
     *
     * @param {*} value The value.
     * @returns {string} The type detected from the value.
     */ static getTypeDescriptorFromValue_(value) {
        let typeName;
        if (value === null) {
            throw new Error("Parameter types must be provided for null values via the 'types' field in query options.");
        }
        if (value instanceof BigQueryDate) {
            typeName = 'DATE';
        } else if (value instanceof BigQueryDatetime) {
            typeName = 'DATETIME';
        } else if (value instanceof BigQueryTime) {
            typeName = 'TIME';
        } else if (value instanceof BigQueryTimestamp) {
            typeName = 'TIMESTAMP';
        } else if (value instanceof Buffer) {
            typeName = 'BYTES';
        } else if (value instanceof Big) {
            if (value.c.length - value.e >= 10) {
                typeName = 'BIGNUMERIC';
            } else {
                typeName = 'NUMERIC';
            }
        } else if (value instanceof BigQueryInt) {
            typeName = 'INT64';
        } else if (value instanceof Geography) {
            typeName = 'GEOGRAPHY';
        } else if (value instanceof BigQueryRange) {
            return {
                type: 'RANGE',
                rangeElementType: {
                    type: value.elementType
                }
            };
        } else if ((0, util_1.isArray)(value)) {
            if (value.length === 0) {
                throw new Error("Parameter types must be provided for empty arrays via the 'types' field in query options.");
            }
            return {
                type: 'ARRAY',
                arrayType: BigQuery.getTypeDescriptorFromValue_(value[0])
            };
        } else if ((0, util_1.isBoolean)(value)) {
            typeName = 'BOOL';
        } else if ((0, util_1.isNumber)(value)) {
            typeName = value % 1 === 0 ? 'INT64' : 'FLOAT64';
        } else if ((0, util_1.isObject)(value)) {
            return {
                type: 'STRUCT',
                structTypes: Object.keys(value).map((prop)=>{
                    return {
                        name: prop,
                        // eslint-disable-next-line @typescript-eslint/no-explicit-any
                        type: BigQuery.getTypeDescriptorFromValue_(value[prop])
                    };
                })
            };
        } else if ((0, util_1.isString)(value)) {
            typeName = 'STRING';
        }
        if (!typeName) {
            throw new Error([
                'This value could not be translated to a BigQuery data type.',
                value
            ].join('\n'));
        }
        return {
            type: typeName
        };
    }
    /**
     * Convert a value into a `queryParameter` object.
     *
     * @private
     *
     * See {@link https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query#request-body| Jobs.query API Reference Docs (see `queryParameters`)}
     *
     * @param {*} value The value.
     * @param {string|ProvidedTypeStruct|ProvidedTypeArray} providedType Provided
     *     query parameter type.
     * @returns {object} A properly-formed `queryParameter` object.
     */ static valueToQueryParameter_(// eslint-disable-next-line @typescript-eslint/no-explicit-any
    value, providedType) {
        if ((0, util_1.isDate)(value)) {
            value = BigQuery.timestamp(value);
        }
        let parameterType;
        if (providedType) {
            parameterType = BigQuery.getTypeDescriptorFromProvidedType_(providedType);
        } else {
            parameterType = BigQuery.getTypeDescriptorFromValue_(value);
        }
        const queryParameter = {
            parameterType,
            parameterValue: {}
        };
        const typeName = queryParameter.parameterType.type;
        if (typeName === 'ARRAY') {
            queryParameter.parameterValue.arrayValues = value.map((itemValue)=>{
                const value = BigQuery._getValue(itemValue, parameterType.arrayType);
                if ((0, util_1.isObject)(value) || (0, util_1.isArray)(value)) {
                    if ((0, util_1.isArray)(providedType)) {
                        providedType = providedType;
                        return BigQuery.valueToQueryParameter_(value, providedType[0]).parameterValue;
                    } else {
                        return BigQuery.valueToQueryParameter_(value).parameterValue;
                    }
                }
                return {
                    value
                };
            });
        } else if (typeName === 'STRUCT') {
            queryParameter.parameterValue.structValues = Object.keys(value).reduce((structValues, prop)=>{
                let nestedQueryParameter;
                if (providedType) {
                    nestedQueryParameter = BigQuery.valueToQueryParameter_(value[prop], providedType[prop]);
                } else {
                    nestedQueryParameter = BigQuery.valueToQueryParameter_(value[prop]);
                }
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                structValues[prop] = nestedQueryParameter.parameterValue;
                return structValues;
            }, {});
        } else if (typeName === 'RANGE') {
            let rangeValue;
            if (value instanceof BigQueryRange) {
                rangeValue = value;
            } else {
                rangeValue = BigQuery.range(value, queryParameter.parameterType?.rangeElementType?.type);
            }
            queryParameter.parameterValue.rangeValue = {
                start: {
                    value: rangeValue.value.start
                },
                end: {
                    value: rangeValue.value.end
                }
            };
        } else if (typeName === 'JSON' && (0, util_1.isObject)(value)) {
            queryParameter.parameterValue.value = JSON.stringify(value);
        } else {
            queryParameter.parameterValue.value = BigQuery._getValue(value, parameterType);
        }
        return queryParameter;
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    static _getValue(value, type) {
        if (value === null) {
            return null;
        }
        if (value.type) type = value;
        return BigQuery._isCustomType(type) ? value.value : value;
    }
    static _isCustomType({ type }) {
        return type.indexOf('TIME') > -1 || type.indexOf('DATE') > -1 || type.indexOf('GEOGRAPHY') > -1 || type.indexOf('RANGE') > -1 || type.indexOf('BigQueryInt') > -1;
    }
    createDataset(id, optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const reqOpts = {
            method: 'POST',
            uri: '/datasets',
            json: extend(true, {
                location: this.location
            }, options, {
                datasetReference: {
                    datasetId: id
                }
            })
        };
        if (options.projectId) {
            reqOpts.projectId = options.projectId;
        }
        this.request(reqOpts, (err, resp)=>{
            if (err) {
                callback(err, null, resp);
                return;
            }
            const dataset = this.dataset(id, options);
            dataset.metadata = resp;
            callback(null, dataset, resp);
        });
    }
    createQueryJob(opts, callback) {
        const options = typeof opts === 'object' ? opts : {
            query: opts
        };
        this.trace_('[createQueryJob]', options, callback);
        if ((!options || !options.query) && !options.pageToken) {
            throw new Error('A SQL query string is required.');
        }
        const query = extend(true, {
            useLegacySql: false
        }, options);
        this.trace_('[createQueryJob]', query);
        if (options.destination) {
            if (!(options.destination instanceof table_1.Table)) {
                throw new Error('Destination must be a Table object.');
            }
            query.destinationTable = {
                datasetId: options.destination.dataset.id,
                projectId: options.destination.dataset.projectId,
                tableId: options.destination.id
            };
            delete query.destination;
        }
        if (query.params) {
            const { parameterMode, params } = this.buildQueryParams_(query.params, query.types);
            query.parameterMode = parameterMode;
            query.queryParameters = params;
            delete query.params;
        }
        const reqOpts = {};
        reqOpts.configuration = {
            query
        };
        if (typeof query.jobTimeoutMs === 'number') {
            reqOpts.configuration.jobTimeoutMs = query.jobTimeoutMs.toString();
            delete query.jobTimeoutMs;
        }
        if (query.dryRun) {
            reqOpts.configuration.dryRun = query.dryRun;
            delete query.dryRun;
        }
        if (query.labels) {
            reqOpts.configuration.labels = query.labels;
            delete query.labels;
        }
        if (query.jobPrefix) {
            reqOpts.jobPrefix = query.jobPrefix;
            delete query.jobPrefix;
        }
        if (query.location) {
            reqOpts.location = query.location;
            delete query.location;
        }
        if (query.jobId) {
            reqOpts.jobId = query.jobId;
            delete query.jobId;
        }
        if (query.reservation) {
            reqOpts.configuration.reservation = query.reservation;
            delete query.reservation;
        }
        this.createJob(reqOpts, callback);
    }
    buildQueryParams_(params, types) {
        if (!params) {
            return {
                parameterMode: undefined,
                params: undefined
            };
        }
        const parameterMode = (0, util_1.isArray)(params) ? 'positional' : 'named';
        const queryParameters = [];
        if (parameterMode === 'named') {
            const namedParams = params;
            for (const namedParameter of Object.getOwnPropertyNames(namedParams)){
                const value = namedParams[namedParameter];
                let queryParameter;
                if (types) {
                    if (!(0, util_1.isObject)(types)) {
                        throw new Error('Provided types must match the value type passed to `params`');
                    }
                    const namedTypes = types;
                    if (namedTypes[namedParameter]) {
                        queryParameter = BigQuery.valueToQueryParameter_(value, namedTypes[namedParameter]);
                    } else {
                        queryParameter = BigQuery.valueToQueryParameter_(value);
                    }
                } else {
                    queryParameter = BigQuery.valueToQueryParameter_(value);
                }
                queryParameter.name = namedParameter;
                queryParameters.push(queryParameter);
            }
        } else {
            if (types) {
                if (!(0, util_1.isArray)(types)) {
                    throw new Error('Provided types must match the value type passed to `params`');
                }
                const positionalTypes = types;
                if (params.length !== types.length) {
                    throw new Error('Incorrect number of parameter types provided.');
                }
                params.forEach((value, i)=>{
                    const queryParameter = BigQuery.valueToQueryParameter_(value, positionalTypes[i]);
                    queryParameters.push(queryParameter);
                });
            } else {
                params.forEach((value)=>{
                    const queryParameter = BigQuery.valueToQueryParameter_(value);
                    queryParameters.push(queryParameter);
                });
            }
        }
        return {
            parameterMode,
            params: queryParameters
        };
    }
    createJob(options, callback) {
        const JOB_ID_PROVIDED = typeof options.jobId !== 'undefined';
        const DRY_RUN = options.configuration?.dryRun ? options.configuration.dryRun : false;
        const reqOpts = Object.assign({}, options);
        let jobId = JOB_ID_PROVIDED ? reqOpts.jobId : (0, crypto_1.randomUUID)();
        if (reqOpts.jobId) {
            delete reqOpts.jobId;
        }
        if (reqOpts.jobPrefix) {
            jobId = reqOpts.jobPrefix + jobId;
            delete reqOpts.jobPrefix;
        }
        reqOpts.jobReference = {
            projectId: this.projectId,
            jobId,
            location: this.location
        };
        if (reqOpts.location) {
            reqOpts.jobReference.location = reqOpts.location;
            delete reqOpts.location;
        }
        if (reqOpts.configuration && reqOpts.reservation) {
            reqOpts.configuration.reservation = reqOpts.reservation;
            delete reqOpts.reservation;
        }
        const job = this.job(jobId, {
            location: reqOpts.jobReference.location
        });
        this.request({
            method: 'POST',
            uri: '/jobs',
            json: reqOpts
        }, async (err, resp)=>{
            const ALREADY_EXISTS_CODE = 409;
            if (err) {
                if (err.code === ALREADY_EXISTS_CODE && !JOB_ID_PROVIDED && !DRY_RUN) {
                    // The last insert attempt flaked, but the API still processed the
                    // request and created the job. Because of our "autoRetry" feature,
                    // we tried the request again, which tried to create it again,
                    // unnecessarily. We will get the job's metadata and treat it as if
                    // it just came back from the create call.
                    err = null;
                    [resp] = await job.getMetadata();
                } else {
                    callback(err, null, resp);
                    return;
                }
            }
            if (resp.status.errors) {
                err = new common_1.util.ApiError({
                    errors: resp.status.errors,
                    response: resp
                });
            }
            // Update the location with the one used by the API.
            job.location = resp.jobReference.location;
            job.metadata = resp;
            callback(err, job, resp);
        });
    }
    /**
     * Create a reference to a dataset.
     *
     * @param {string} id ID of the dataset.
     * @param {object} [options] Dataset options.
     * @param {string} [options.projectId] The GCP project ID.
     * @param {string} [options.location] The geographic location of the dataset.
     *      Required except for US and EU.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     * const dataset = bigquery.dataset('higher_education');
     * ```
     */ dataset(id, options) {
        if (typeof id !== 'string') {
            throw new TypeError('A dataset ID is required.');
        }
        if (this.location) {
            options = extend({
                location: this.location
            }, options);
        }
        return new dataset_1.Dataset(this, id, options);
    }
    getDatasets(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        const reqOpts = {
            uri: '/datasets',
            qs: options
        };
        if (options.projectId) {
            reqOpts.projectId = options.projectId;
        }
        this.request(reqOpts, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.nextPageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.nextPageToken
                });
            }
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const datasets = (resp.datasets || []).map((dataset)=>{
                const dsOpts = {
                    location: dataset.location
                };
                if (options.projectId) {
                    dsOpts.projectId = options.projectId;
                }
                const ds = this.dataset(dataset.datasetReference.datasetId, dsOpts);
                ds.metadata = dataset;
                return ds;
            });
            callback(null, datasets, nextQuery, resp);
        });
    }
    getJobs(optionsOrCallback, cb) {
        const options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        this.request({
            uri: '/jobs',
            qs: options,
            useQuerystring: true
        }, (err, resp)=>{
            if (err) {
                callback(err, null, null, resp);
                return;
            }
            let nextQuery = null;
            if (resp.nextPageToken) {
                nextQuery = Object.assign({}, options, {
                    pageToken: resp.nextPageToken
                });
            }
            const jobs = (resp.jobs || []).map((jobObject)=>{
                const job = this.job(jobObject.jobReference.jobId, {
                    location: jobObject.jobReference.location
                });
                job.metadata = jobObject;
                return job;
            });
            callback(null, jobs, nextQuery, resp);
        });
    }
    /**
     * Create a reference to an existing job.
     *
     * @param {string} id ID of the job.
     * @param {object} [options] Configuration object.
     * @param {string} [options.location] The geographic location of the job.
     *      Required except for US and EU.
     *
     * @example
     * ```
     * const {BigQuery} = require('@google-cloud/bigquery');
     * const bigquery = new BigQuery();
     *
     * const myExistingJob = bigquery.job('job-id');
     * ```
     */ job(id, options) {
        if (this.location) {
            options = extend({
                location: this.location
            }, options);
        }
        return new job_1.Job(this, id, options);
    }
    query(query, optionsOrCallback, cb) {
        let options = typeof optionsOrCallback === 'object' ? optionsOrCallback : {};
        const queryOpts = typeof query === 'object' ? {
            wrapIntegers: query.wrapIntegers,
            parseJSON: query.parseJSON
        } : {};
        const callback = typeof optionsOrCallback === 'function' ? optionsOrCallback : cb;
        this.trace_('[query]', query, options);
        const queryReq = this.buildQueryRequest_(query, options);
        this.trace_('[query] queryReq', queryReq);
        if (!queryReq) {
            this.createQueryJob(query, (err, job, resp)=>{
                if (err) {
                    callback(err, null, resp);
                    return;
                }
                if (typeof query === 'object' && query.dryRun) {
                    callback(null, [], resp);
                    return;
                }
                // The Job is important for the `queryAsStream_` method, so a new query
                // isn't created each time results are polled for.
                options = extend({
                    job
                }, queryOpts, options);
                job.getQueryResults(options, callback);
            });
            return;
        }
        void this.runJobsQuery(queryReq, (err, job, res)=>{
            this.trace_('[runJobsQuery callback]: ', query, err, job, res);
            if (err) {
                callback(err, null, job);
                return;
            }
            options = extend({
                job
            }, queryOpts, options);
            if (res && res.jobComplete) {
                let rows = [];
                if (res.schema && res.rows) {
                    rows = BigQuery.mergeSchemaWithRows_(res.schema, res.rows, {
                        wrapIntegers: options.wrapIntegers || false,
                        parseJSON: options.parseJSON
                    });
                    delete res.rows;
                }
                this.trace_('[runJobsQuery] job complete');
                options._cachedRows = rows;
                options._cachedResponse = res;
                if (res.pageToken) {
                    this.trace_('[runJobsQuery] has more pages');
                    options.pageToken = res.pageToken;
                } else {
                    this.trace_('[runJobsQuery] no more pages');
                }
                job.getQueryResults(options, callback);
                return;
            }
            // If timeout override was provided, return error.
            if (queryReq.timeoutMs) {
                const err = new Error(`The query did not complete before ${queryReq.timeoutMs}ms`);
                callback(err, null, job);
                return;
            }
            delete options.timeoutMs;
            this.trace_('[runJobsQuery] job not complete');
            job.getQueryResults(options, callback);
        });
    }
    /**
     * Check if the given Query can run using the `jobs.query` endpoint.
     * Returns a bigquery.IQueryRequest that can be used to call `jobs.query`.
     * Return undefined if is not possible to convert to a bigquery.IQueryRequest.
     *
     * @param query string | Query
     * @param options QueryOptions
     * @returns bigquery.IQueryRequest | undefined
     */ buildQueryRequest_(query, options) {
        if (process.env.FAST_QUERY_PATH === 'DISABLED') {
            return undefined;
        }
        const queryObj = typeof query === 'string' ? {
            query: query
        } : query;
        this.trace_('[buildQueryRequest]', query, options, queryObj);
        // This is a denylist of settings which prevent us from composing an equivalent
        // bq.QueryRequest due to differences between configuration parameters accepted
        // by jobs.insert vs jobs.query.
        if (!!queryObj.destination || !!queryObj.tableDefinitions || !!queryObj.createDisposition || !!queryObj.writeDisposition || !!queryObj.priority && queryObj.priority !== 'INTERACTIVE' || queryObj.useLegacySql || !!queryObj.maximumBillingTier || !!queryObj.timePartitioning || !!queryObj.rangePartitioning || !!queryObj.clustering || !!queryObj.destinationEncryptionConfiguration || !!queryObj.schemaUpdateOptions || !!queryObj.jobTimeoutMs || // User has defined the jobID generation behavior
        !!queryObj.jobId) {
            return undefined;
        }
        if (queryObj.dryRun) {
            return undefined;
        }
        if (options.job) {
            return undefined;
        }
        const req = {
            useQueryCache: queryObj.useQueryCache,
            labels: queryObj.labels,
            defaultDataset: queryObj.defaultDataset,
            createSession: queryObj.createSession,
            maximumBytesBilled: queryObj.maximumBytesBilled,
            timeoutMs: options.timeoutMs,
            location: queryObj.location || options.location,
            formatOptions: {
                useInt64Timestamp: true
            },
            maxResults: queryObj.maxResults || options.maxResults,
            query: queryObj.query,
            useLegacySql: false,
            requestId: (0, crypto_1.randomUUID)(),
            jobCreationMode: this._defaultJobCreationMode,
            reservation: queryObj.reservation,
            continuous: queryObj.continuous,
            destinationEncryptionConfiguration: queryObj.destinationEncryptionConfiguration,
            writeIncrementalResults: queryObj.writeIncrementalResults,
            connectionProperties: queryObj.connectionProperties,
            preserveNulls: queryObj.preserveNulls
        };
        if (queryObj.jobCreationMode) {
            // override default job creation mode
            req.jobCreationMode = queryObj.jobCreationMode;
        }
        const { parameterMode, params } = this.buildQueryParams_(queryObj.params, queryObj.types);
        if (params) {
            req.queryParameters = params;
        }
        if (parameterMode) {
            req.parameterMode = parameterMode;
        }
        return req;
    }
    runJobsQuery(req, callback) {
        this.trace_('[runJobsQuery]', req, callback);
        this.request({
            method: 'POST',
            uri: '/queries',
            json: req
        }, async (err, res)=>{
            this.trace_('jobs.query res:', res, err);
            if (err) {
                callback(err, null, res);
                return;
            }
            let job = null;
            if (res.jobReference) {
                const jobRef = res.jobReference;
                job = this.job(jobRef.jobId, {
                    location: jobRef.location
                });
            } else if (res.queryId) {
                job = this.job(res.queryId); // stateless query
            }
            callback(null, job, res);
        });
    }
    /**
     * This method will be called by `createQueryStream()`. It is required to
     * properly set the `autoPaginate` option value.
     *
     * @private
     */ queryAsStream_(query, callback) {
        if (query.job) {
            query.job.getQueryResults(query, callback);
            return;
        }
        const { location, maxResults, pageToken, wrapIntegers, parseJSON } = query;
        const opts = {
            location,
            maxResults,
            pageToken,
            wrapIntegers,
            parseJSON,
            autoPaginate: false
        };
        delete query.location;
        delete query.maxResults;
        delete query.pageToken;
        delete query.wrapIntegers;
        delete query.parseJSON;
        this.query(query, opts, callback);
    }
    static setLogFunction = logger_1.setLogFunction;
}
exports.BigQuery = BigQuery;
/*! Developer Documentation
 *
 * These methods can be auto-paginated.
 */ paginator_1.paginator.extend(BigQuery, [
    'getDatasets',
    'getJobs'
]);
/*! Developer Documentation
 *
 * All async methods (except for streams) will return a Promise in the event
 * that a callback is omitted.
 */ (0, promisify_1.promisifyAll)(BigQuery, {
    exclude: [
        'dataset',
        'date',
        'datetime',
        'geography',
        'int',
        'job',
        'time',
        'timestamp',
        'range'
    ]
});
function convertSchemaFieldValue(schemaField, // eslint-disable-next-line @typescript-eslint/no-explicit-any
value, options) {
    if (value === null) {
        return value;
    }
    switch(schemaField.type){
        case 'BOOLEAN':
        case 'BOOL':
            {
                value = value.toLowerCase() === 'true';
                break;
            }
        case 'BYTES':
            {
                value = Buffer.from(value, 'base64');
                break;
            }
        case 'FLOAT':
        case 'FLOAT64':
            {
                value = Number(value);
                break;
            }
        case 'INTEGER':
        case 'INT64':
            {
                const { wrapIntegers } = options;
                value = wrapIntegers ? typeof wrapIntegers === 'object' ? BigQuery.int({
                    integerValue: value,
                    schemaFieldName: schemaField.name
                }, wrapIntegers).valueOf() : BigQuery.int(value) : Number(value);
                break;
            }
        case 'NUMERIC':
            {
                value = new Big(value);
                break;
            }
        case 'BIGNUMERIC':
            {
                value = new Big(value);
                break;
            }
        case 'RECORD':
            {
                value = BigQuery.mergeSchemaWithRows_(schemaField, value, options).pop();
                break;
            }
        case 'DATE':
            {
                value = BigQuery.date(value);
                break;
            }
        case 'DATETIME':
            {
                value = BigQuery.datetime(value);
                break;
            }
        case 'TIME':
            {
                value = BigQuery.time(value);
                break;
            }
        case 'TIMESTAMP':
            {
                const pd = new precise_date_1.PreciseDate();
                pd.setFullTime(precise_date_1.PreciseDate.parseFull(BigInt(value) * BigInt(1000)));
                value = BigQuery.timestamp(pd);
                break;
            }
        case 'GEOGRAPHY':
            {
                value = BigQuery.geography(value);
                break;
            }
        case 'JSON':
            {
                const { parseJSON } = options;
                value = parseJSON ? JSON.parse(value) : value;
                break;
            }
        case 'RANGE':
            {
                value = BigQueryRange.fromSchemaValue_(value, schemaField.rangeElementType.type);
                break;
            }
        default:
            break;
    }
    return value;
}
/**
 * Range class for BigQuery.
 * A range represents contiguous range between two dates, datetimes, or timestamps.
 * The lower and upper bound for the range are optional.
 * The lower bound is inclusive and the upper bound is exclusive.
 * See https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#range_literals
 */ class BigQueryRange {
    elementType;
    start;
    end;
    constructor(value, elementType){
        if (typeof value === 'string') {
            if (!elementType) {
                throw new Error('invalid RANGE. Element type required when using RANGE API string.');
            }
            const [start, end] = BigQueryRange.fromStringValue_(value);
            this.start = this.convertElement_(start, elementType);
            this.end = this.convertElement_(end, elementType);
            this.elementType = elementType;
        } else {
            const { start, end } = value;
            if (start && end) {
                if (typeof start !== typeof end) {
                    throw Error('upper and lower bound on a RANGE should be of the same type.');
                }
            }
            const inferredType = {
                BigQueryDate: 'DATE',
                BigQueryDatetime: 'DATETIME',
                BigQueryTimestamp: 'TIMESTAMP'
            }[(start || end || Object).constructor.name] || elementType;
            this.start = this.convertElement_(start, inferredType);
            this.end = this.convertElement_(end, inferredType);
            this.elementType = inferredType;
        }
    }
    /*
     * Get Range string representation used by the BigQuery API.
     */ get apiValue() {
        return `[${this.start ? this.start.value : 'UNBOUNDED'}, ${this.end ? this.end.value : 'UNBOUNDED'})`;
    }
    /*
     * Get Range literal representation accordingly to
     * https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#range_literals
     */ get literalValue() {
        return `RANGE<${this.elementType}> ${this.apiValue}`;
    }
    get value() {
        return {
            start: this.start ? this.start.value : 'UNBOUNDED',
            end: this.end ? this.end.value : 'UNBOUNDED'
        };
    }
    static fromStringValue_(value) {
        let cleanedValue = value;
        if (cleanedValue.startsWith('[') || cleanedValue.startsWith('(')) {
            cleanedValue = cleanedValue.substring(1);
        }
        if (cleanedValue.endsWith(')') || cleanedValue.endsWith(']')) {
            cleanedValue = cleanedValue.substring(0, cleanedValue.length - 1);
        }
        const parts = cleanedValue.split(',');
        if (parts.length !== 2) {
            throw new Error('invalid RANGE. See RANGE literal format docs for more information.');
        }
        const [start, end] = parts.map((s)=>s.trim());
        return [
            start,
            end
        ];
    }
    static fromSchemaValue_(value, elementType) {
        const [start, end] = BigQueryRange.fromStringValue_(value);
        const convertRangeSchemaValue = (value)=>{
            if (value === 'UNBOUNDED' || value === 'NULL') {
                return null;
            }
            return convertSchemaFieldValue({
                type: elementType
            }, value, {
                wrapIntegers: false
            });
        };
        return BigQuery.range({
            start: convertRangeSchemaValue(start),
            end: convertRangeSchemaValue(end)
        }, elementType);
    }
    convertElement_(value, elementType) {
        if (typeof value === 'string') {
            if (value === 'UNBOUNDED' || value === 'NULL') {
                return undefined;
            }
            switch(elementType){
                case 'DATE':
                    return new BigQueryDate(value);
                case 'DATETIME':
                    return new BigQueryDatetime(value);
                case 'TIMESTAMP':
                    return new BigQueryTimestamp(value);
            }
            return undefined;
        }
        return value;
    }
}
exports.BigQueryRange = BigQueryRange;
/**
 * Date class for BigQuery.
 */ class BigQueryDate {
    value;
    constructor(value){
        if (typeof value === 'object') {
            value = BigQuery.datetime(value).value;
        }
        this.value = value;
    }
}
exports.BigQueryDate = BigQueryDate;
/**
 * Geography class for BigQuery.
 */ class Geography {
    value;
    constructor(value){
        this.value = value;
    }
}
exports.Geography = Geography;
/**
 * Timestamp class for BigQuery.
 *
 * The recommended input here is a `Date` or `PreciseDate` class.
 * If passing as a `string`, it should be Timestamp literals: https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#timestamp_literals.
 * When passing a `number` input, it should be epoch seconds in float representation.
 *
 */ class BigQueryTimestamp {
    value;
    constructor(value){
        let pd;
        if (value instanceof precise_date_1.PreciseDate) {
            pd = value;
        } else if (value instanceof Date) {
            pd = new precise_date_1.PreciseDate(value);
        } else if (typeof value === 'string') {
            if (/^\d{4}-\d{1,2}-\d{1,2}/.test(value)) {
                pd = new precise_date_1.PreciseDate(value);
            } else {
                const floatValue = Number.parseFloat(value);
                if (!Number.isNaN(floatValue)) {
                    pd = this.fromFloatValue_(floatValue);
                } else {
                    pd = new precise_date_1.PreciseDate(value);
                }
            }
        } else {
            pd = this.fromFloatValue_(value);
        }
        // to keep backward compatibility, only converts with microsecond
        // precision if needed.
        if (pd.getMicroseconds() > 0) {
            this.value = pd.toISOString();
        } else {
            this.value = new Date(pd.getTime()).toJSON();
        }
    }
    fromFloatValue_(value) {
        const secs = Math.trunc(value);
        // Timestamps in BigQuery have microsecond precision, so we must
        // return a round number of microseconds.
        const micros = Math.trunc((value - secs) * 1e6 + 0.5);
        const pd = new precise_date_1.PreciseDate([
            secs,
            micros * 1000
        ]);
        return pd;
    }
}
exports.BigQueryTimestamp = BigQueryTimestamp;
/**
 * Datetime class for BigQuery.
 */ class BigQueryDatetime {
    value;
    constructor(value){
        if (typeof value === 'object') {
            let time;
            if (value.hours) {
                time = BigQuery.time(value).value;
            }
            const y = value.year;
            const m = value.month;
            const d = value.day;
            time = time ? ' ' + time : '';
            value = `${y}-${m}-${d}${time}`;
        } else {
            value = value.replace(/^(.*)T(.*)Z$/, '$1 $2');
        }
        this.value = value;
    }
}
exports.BigQueryDatetime = BigQueryDatetime;
/**
 * Time class for BigQuery.
 */ class BigQueryTime {
    value;
    constructor(value){
        if (typeof value === 'object') {
            const h = value.hours;
            const m = value.minutes || 0;
            const s = value.seconds || 0;
            const f = value.fractional !== undefined ? '.' + value.fractional : '';
            value = `${h}:${m}:${s}${f}`;
        }
        this.value = value;
    }
}
exports.BigQueryTime = BigQueryTime;
/**
 * Build a BigQueryInt object. For long integers, a string can be provided.
 *
 * @class
 * @param {string|number|IntegerTypeCastValue} value The 'INT64' value.
 * @param {object} [typeCastOptions] Configuration to convert
 *     values of 'INT64' type to a custom value. Must provide an
 *     `integerTypeCastFunction` to handle conversion.
 * @param {function} typeCastOptions.integerTypeCastFunction A custom user
 *     provided function to convert value.
 * @param {string|string[]} [typeCastOptions.fields] Schema field
 *     names to be converted using `integerTypeCastFunction`.
 *
 * @example
 * ```
 * const {BigQuery} = require('@google-cloud/bigquery');
 * const bigquery = new BigQuery();
 * const anInt = bigquery.int(7);
 * ```
 */ class BigQueryInt extends Number {
    type;
    value;
    typeCastFunction;
    _schemaFieldName;
    constructor(value, typeCastOptions){
        super(typeof value === 'object' ? value.integerValue : value);
        this._schemaFieldName = typeof value === 'object' ? value.schemaFieldName : undefined;
        this.value = typeof value === 'object' ? value.integerValue.toString() : value.toString();
        this.type = 'BigQueryInt';
        if (typeCastOptions) {
            if (typeof typeCastOptions.integerTypeCastFunction !== 'function') {
                throw new Error('integerTypeCastFunction is not a function or was not provided.');
            }
            const typeCastFields = typeCastOptions.fields ? (0, util_1.toArray)(typeCastOptions.fields) : undefined;
            let customCast = true;
            if (typeCastFields) {
                customCast = this._schemaFieldName ? typeCastFields.includes(this._schemaFieldName) ? true : false : false;
            }
            customCast && (this.typeCastFunction = typeCastOptions.integerTypeCastFunction);
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    valueOf() {
        const shouldCustomCast = this.typeCastFunction ? true : false;
        if (shouldCustomCast) {
            try {
                return this.typeCastFunction(this.value);
            } catch (error) {
                if (error instanceof Error) {
                    error.message = `integerTypeCastFunction threw an error:\n\n  - ${error.message}`;
                }
                throw error;
            }
        } else {
            return BigQuery.decodeIntegerValue_({
                integerValue: this.value,
                schemaFieldName: this._schemaFieldName
            });
        }
    }
    toJSON() {
        return {
            type: this.type,
            value: this.value
        };
    }
}
exports.BigQueryInt = BigQueryInt; //# sourceMappingURL=bigquery.js.map
}),
"[project]/node_modules/@google-cloud/bigquery/build/src/index.js [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/*!
 * Copyright 2019 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Table = exports.RowQueue = exports.RowBatch = exports.Routine = exports.Model = exports.Job = exports.Dataset = exports.PROTOCOL_REGEX = exports.Geography = exports.common = exports.BigQueryTimestamp = exports.BigQueryTime = exports.BigQueryInt = exports.BigQueryDatetime = exports.BigQueryDate = exports.BigQuery = void 0;
var bigquery_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/bigquery.js [app-route] (ecmascript)");
Object.defineProperty(exports, "BigQuery", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQuery;
    }
});
Object.defineProperty(exports, "BigQueryDate", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQueryDate;
    }
});
Object.defineProperty(exports, "BigQueryDatetime", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQueryDatetime;
    }
});
Object.defineProperty(exports, "BigQueryInt", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQueryInt;
    }
});
Object.defineProperty(exports, "BigQueryTime", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQueryTime;
    }
});
Object.defineProperty(exports, "BigQueryTimestamp", {
    enumerable: true,
    get: function() {
        return bigquery_1.BigQueryTimestamp;
    }
});
Object.defineProperty(exports, "common", {
    enumerable: true,
    get: function() {
        return bigquery_1.common;
    }
});
Object.defineProperty(exports, "Geography", {
    enumerable: true,
    get: function() {
        return bigquery_1.Geography;
    }
});
Object.defineProperty(exports, "PROTOCOL_REGEX", {
    enumerable: true,
    get: function() {
        return bigquery_1.PROTOCOL_REGEX;
    }
});
var dataset_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/dataset.js [app-route] (ecmascript)");
Object.defineProperty(exports, "Dataset", {
    enumerable: true,
    get: function() {
        return dataset_1.Dataset;
    }
});
var job_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/job.js [app-route] (ecmascript)");
Object.defineProperty(exports, "Job", {
    enumerable: true,
    get: function() {
        return job_1.Job;
    }
});
var model_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/model.js [app-route] (ecmascript)");
Object.defineProperty(exports, "Model", {
    enumerable: true,
    get: function() {
        return model_1.Model;
    }
});
var routine_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/routine.js [app-route] (ecmascript)");
Object.defineProperty(exports, "Routine", {
    enumerable: true,
    get: function() {
        return routine_1.Routine;
    }
});
var rowBatch_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/rowBatch.js [app-route] (ecmascript)");
Object.defineProperty(exports, "RowBatch", {
    enumerable: true,
    get: function() {
        return rowBatch_1.RowBatch;
    }
});
var rowQueue_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/rowQueue.js [app-route] (ecmascript)");
Object.defineProperty(exports, "RowQueue", {
    enumerable: true,
    get: function() {
        return rowQueue_1.RowQueue;
    }
});
var table_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/bigquery/build/src/table.js [app-route] (ecmascript)");
Object.defineProperty(exports, "Table", {
    enumerable: true,
    get: function() {
        return table_1.Table;
    }
}); //# sourceMappingURL=index.js.map
}),
];

//# sourceMappingURL=node_modules_%40google-cloud_bigquery_0f09d6e4._.js.map